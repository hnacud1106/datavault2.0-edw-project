[0m12:36:01.111076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e47e050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2b9e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e47f110>]}


============================== 12:36:01.114843 | 135220b1-4c78-4dc4-9aee-f4990e38e760 ==============================
[0m12:36:01.114843 [info ] [MainThread]: Running with dbt=1.10.6
[0m12:36:01.115289 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:36:01.119542 [info ] [MainThread]: dbt version: 1.10.6
[0m12:36:01.119895 [info ] [MainThread]: python version: 3.11.5
[0m12:36:01.120192 [info ] [MainThread]: python path: /usr/local/bin/python
[0m12:36:01.120465 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.31
[0m12:36:01.153932 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt
[0m12:36:01.154466 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt/profiles.yml
[0m12:36:01.154849 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt/dbt_project.yml
[0m12:36:01.155269 [info ] [MainThread]: adapter type: clickhouse
[0m12:36:01.155560 [info ] [MainThread]: adapter version: 1.9.2
[0m12:36:01.204093 [info ] [MainThread]: Configuration:
[0m12:36:01.204587 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:36:01.204914 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:36:01.205294 [info ] [MainThread]: Required dependencies:
[0m12:36:01.205656 [debug] [MainThread]: Executing "git --help"
[0m12:36:01.206743 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m12:36:01.207084 [info ] [MainThread]: Connection:
[0m12:36:01.207403 [info ] [MainThread]:   driver: None
[0m12:36:01.207710 [info ] [MainThread]:   host: clickhouse-edw
[0m12:36:01.207991 [info ] [MainThread]:   port: 8123
[0m12:36:01.208276 [info ] [MainThread]:   user: default
[0m12:36:01.208584 [info ] [MainThread]:   schema: edw
[0m12:36:01.208876 [info ] [MainThread]:   retries: 1
[0m12:36:01.209150 [info ] [MainThread]:   cluster: None
[0m12:36:01.209437 [info ] [MainThread]:   database_engine: None
[0m12:36:01.209729 [info ] [MainThread]:   cluster_mode: False
[0m12:36:01.210026 [info ] [MainThread]:   secure: False
[0m12:36:01.210305 [info ] [MainThread]:   verify: False
[0m12:36:01.210578 [info ] [MainThread]:   client_cert: None
[0m12:36:01.210866 [info ] [MainThread]:   client_cert_key: None
[0m12:36:01.211139 [info ] [MainThread]:   connect_timeout: 10
[0m12:36:01.211450 [info ] [MainThread]:   send_receive_timeout: 300
[0m12:36:01.211732 [info ] [MainThread]:   sync_request_timeout: 5
[0m12:36:01.212013 [info ] [MainThread]:   compress_block_size: 1048576
[0m12:36:01.212282 [info ] [MainThread]:   compression: 
[0m12:36:01.212550 [info ] [MainThread]:   check_exchange: True
[0m12:36:01.212835 [info ] [MainThread]:   custom_settings: {'async_insert': 1, 'wait_for_async_insert': 1}
[0m12:36:01.213102 [info ] [MainThread]:   use_lw_deletes: False
[0m12:36:01.213371 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m12:36:01.213631 [info ] [MainThread]:   tcp_keepalive: False
[0m12:36:01.214009 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m12:36:01.247709 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m12:36:01.248165 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:36:01.508550 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m12:36:01.509966 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:01.521130 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:36:01.521508 [info ] [MainThread]: [31m1 check failed:[0m
[0m12:36:01.521756 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m12:36:01.522385 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.4393893, "process_in_blocks": "2504", "process_kernel_time": 0.135117, "process_mem_max_rss": "177600", "process_out_blocks": "1409", "process_user_time": 1.902649}
[0m12:36:01.522756 [debug] [MainThread]: Command `dbt debug` failed at 12:36:01.522706 after 0.44 seconds
[0m12:36:01.523054 [debug] [MainThread]: Connection 'debug' was left open.
[0m12:36:01.523316 [debug] [MainThread]: On debug: Close
[0m12:36:01.523582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e7fbb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e445c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff644b16d0>]}
[0m12:36:01.523863 [debug] [MainThread]: Flushing usage events
[0m12:36:02.673215 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:36:03.981890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa99c9350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa99ca510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9e17090>]}


============================== 12:36:03.985501 | dbb61650-2cac-468f-9550-7d9257f34f0a ==============================
[0m12:36:03.985501 [info ] [MainThread]: Running with dbt=1.10.6
[0m12:36:03.985960 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'invocation_command': 'dbt run --select staging', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:36:04.088784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa99c9650>]}
[0m12:36:04.117795 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9fe4390>]}
[0m12:36:04.118464 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m12:36:04.153182 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m12:36:04.218659 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:36:04.219143 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:36:04.239953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa947f350>]}
[0m12:36:04.287629 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:04.289392 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:04.301298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa993f490>]}
[0m12:36:04.302033 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m12:36:04.302393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9745510>]}
[0m12:36:04.303411 [info ] [MainThread]: 
[0m12:36:04.303773 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:36:04.304064 [info ] [MainThread]: 
[0m12:36:04.304468 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:36:04.307815 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:36:04.314398 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:04.630939 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:36:04.632811 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:04.641454 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m12:36:04.646140 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m12:36:04.652494 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:36:04.654959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff87be7310>]}
[0m12:36:04.660683 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product
[0m12:36:04.663577 [info ] [Thread-1 (]: 1 of 2 START sql view model `edw`.`stg_product` ................................ [RUN]
[0m12:36:04.664302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.stg_product)
[0m12:36:04.664905 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product
[0m12:36:04.673163 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product"
[0m12:36:04.675310 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product
[0m12:36:04.690102 [debug] [Thread-1 (]: Creating new relation stg_product
[0m12:36:04.699153 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product"
[0m12:36:04.701864 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product"} */


  create or replace view `edw`.`stg_product` 
  
    
  
  
    
    
  as (
    

WITH source_data AS (
    SELECT DISTINCT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        deal_name,
        load_date,
        record_source,
        product_hash_key,
        deal_hash_key,
        product_deal_hash_key,
        product_hash_diff
    FROM `edw`.`stg_products`
),

normalized_products AS (
    SELECT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        product_hash_key,
        product_hash_diff,
        max(load_date) AS load_date,
        max(record_source) AS record_source
    FROM source_data
    GROUP BY
        product_base_id, product_name, product_description,
        category, brand, product_rating, product_image,
        shop_name, shop_link, revenue, month, price, quantity,
        product_hash_key, product_hash_diff
)

SELECT * FROM normalized_products
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m12:36:04.708852 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:36:04.721486 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff869e9c10>]}
[0m12:36:04.722248 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `edw`.`stg_product` ........................... [[32mOK[0m in 0.06s]
[0m12:36:04.722779 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product
[0m12:36:04.723217 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product_deals
[0m12:36:04.723786 [info ] [Thread-1 (]: 2 of 2 START sql view model `edw`.`stg_product_deals` .......................... [RUN]
[0m12:36:04.724187 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.stg_product, now model.clickhouse_edw.stg_product_deals)
[0m12:36:04.724522 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product_deals
[0m12:36:04.726763 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product_deals"
[0m12:36:04.727977 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product_deals
[0m12:36:04.729681 [debug] [Thread-1 (]: Creating new relation stg_product_deals
[0m12:36:04.730495 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product_deals"
[0m12:36:04.731508 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product_deals: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product_deals"} */


  create or replace view `edw`.`stg_product_deals` 
  
    
  
  
    
    
  as (
    

SELECT DISTINCT
    product_base_id,
    deal_name,
    product_hash_key,
    deal_hash_key,
    product_deal_hash_key,
    max(load_date) AS load_date,
    max(record_source) AS record_source
FROM `edw`.`stg_products`
GROUP BY
    product_base_id, deal_name,
    product_hash_key, deal_hash_key, product_deal_hash_key
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m12:36:04.734288 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:04.735819 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dbb61650-2cac-468f-9550-7d9257f34f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8694c250>]}
[0m12:36:04.736334 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `edw`.`stg_product_deals` ..................... [[32mOK[0m in 0.01s]
[0m12:36:04.736776 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product_deals
[0m12:36:04.737866 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:36:04.738202 [debug] [MainThread]: Connection 'model.clickhouse_edw.stg_product_deals' was left open.
[0m12:36:04.738507 [debug] [MainThread]: On model.clickhouse_edw.stg_product_deals: Close
[0m12:36:04.738916 [info ] [MainThread]: 
[0m12:36:04.739356 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m12:36:04.739945 [debug] [MainThread]: Command end result
[0m12:36:04.809665 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:04.811429 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:04.815408 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m12:36:04.815745 [info ] [MainThread]: 
[0m12:36:04.816116 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:36:04.816414 [info ] [MainThread]: 
[0m12:36:04.816730 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m12:36:04.817456 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.86190313, "process_in_blocks": "712", "process_kernel_time": 0.156153, "process_mem_max_rss": "184964", "process_out_blocks": "2142", "process_user_time": 2.117518}
[0m12:36:04.818036 [debug] [MainThread]: Command `dbt run` succeeded at 12:36:04.817936 after 0.86 seconds
[0m12:36:04.818461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffade0c250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaddb89d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffadd8d8d0>]}
[0m12:36:04.818842 [debug] [MainThread]: Flushing usage events
[0m12:36:06.117639 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:36:07.433561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5876410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5d17290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5876ad0>]}


============================== 12:36:07.437631 | cde1174d-c166-4496-ad19-86fdee889b8b ==============================
[0m12:36:07.437631 [info ] [MainThread]: Running with dbt=1.10.6
[0m12:36:07.438242 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select vault.hubs', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:36:07.538322 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5676890>]}
[0m12:36:07.569758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5ee4510>]}
[0m12:36:07.570445 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m12:36:07.610707 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m12:36:07.680844 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:36:07.681363 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:36:07.701600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5676890>]}
[0m12:36:07.751586 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:07.753338 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:07.764853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5443b10>]}
[0m12:36:07.765446 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m12:36:07.766090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa569acd0>]}
[0m12:36:07.767308 [info ] [MainThread]: 
[0m12:36:07.767699 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:36:07.768016 [info ] [MainThread]: 
[0m12:36:07.768434 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:36:07.771893 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:36:07.778720 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:08.041729 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:36:08.042990 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:08.051004 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m12:36:08.054895 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m12:36:08.057467 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:08.059495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9c904dd0>]}
[0m12:36:08.062868 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_deal
[0m12:36:08.063585 [info ] [Thread-1 (]: 1 of 2 START sql incremental model `edw`.`hub_deal` ............................ [RUN]
[0m12:36:08.064512 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.hub_deal)
[0m12:36:08.065153 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_deal
[0m12:36:08.077735 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_deal"
[0m12:36:08.079974 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_deal
[0m12:36:08.114974 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

    select name, type from system.columns where table = 'hub_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m12:36:08.120992 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:08.129842 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_deal"
[0m12:36:08.142548 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

        insert into `edw`.`hub_deal`
        ("deal_hash_key", "deal_business_key", "load_date", "record_source")

WITH deal_data AS (
    SELECT DISTINCT
        deal_name,
        deal_hash_key,
        load_date,
        record_source
    FROM `edw`.`stg_product_deals`
    WHERE deal_name IS NOT NULL
)

SELECT
    deal_hash_key,
    deal_name AS deal_business_key,
    load_date,
    record_source
FROM deal_data


WHERE deal_hash_key NOT IN (
    SELECT deal_hash_key
    FROM `edw`.`hub_deal`
)

      ...
[0m12:36:08.171415 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:36:08.196979 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82a18090>]}
[0m12:36:08.199628 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model `edw`.`hub_deal` ....................... [[32mOK[0m in 0.13s]
[0m12:36:08.206093 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_deal
[0m12:36:08.209095 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_product
[0m12:36:08.211518 [info ] [Thread-1 (]: 2 of 2 START sql incremental model `edw`.`hub_product` ......................... [RUN]
[0m12:36:08.215647 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.hub_deal, now model.clickhouse_edw.hub_product)
[0m12:36:08.220585 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_product
[0m12:36:08.230647 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_product"
[0m12:36:08.237528 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_product
[0m12:36:08.247988 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

    select name, type from system.columns where table = 'hub_product'
    
      and database = 'edw'
    
    order by position
  ...
[0m12:36:08.253747 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:08.256774 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_product"
[0m12:36:08.290371 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

        insert into `edw`.`hub_product`
        ("product_hash_key", "product_business_key", "load_date", "record_source")

SELECT DISTINCT
    product_hash_key,
    product_base_id AS product_business_key,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE product_hash_key NOT IN (
    SELECT product_hash_key
    FROM `edw`.`hub_product`
)

      ...
[0m12:36:08.309972 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:36:08.312425 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cde1174d-c166-4496-ad19-86fdee889b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa40557d0>]}
[0m12:36:08.313333 [info ] [Thread-1 (]: 2 of 2 OK created sql incremental model `edw`.`hub_product` .................... [[32mOK[0m in 0.10s]
[0m12:36:08.314073 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_product
[0m12:36:08.315545 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:36:08.318614 [debug] [MainThread]: Connection 'model.clickhouse_edw.hub_product' was left open.
[0m12:36:08.320615 [debug] [MainThread]: On model.clickhouse_edw.hub_product: Close
[0m12:36:08.321436 [info ] [MainThread]: 
[0m12:36:08.322026 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 0.55 seconds (0.55s).
[0m12:36:08.323014 [debug] [MainThread]: Command end result
[0m12:36:08.448481 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:08.452157 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:08.459540 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m12:36:08.460864 [info ] [MainThread]: 
[0m12:36:08.462160 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:36:08.463207 [info ] [MainThread]: 
[0m12:36:08.464022 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m12:36:08.466891 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0627253, "process_in_blocks": "0", "process_kernel_time": 0.14028, "process_mem_max_rss": "186696", "process_out_blocks": "2133", "process_user_time": 2.402804}
[0m12:36:08.467474 [debug] [MainThread]: Command `dbt run` succeeded at 12:36:08.467406 after 1.06 seconds
[0m12:36:08.467848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9c94250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9c409d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9c158d0>]}
[0m12:36:08.468193 [debug] [MainThread]: Flushing usage events
[0m12:36:09.802355 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:36:11.073167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e138fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e4cf390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e3209d0>]}


============================== 12:36:11.076944 | 54810196-94d2-44ed-a2f8-ae26f2fb9962 ==============================
[0m12:36:11.076944 [info ] [MainThread]: Running with dbt=1.10.6
[0m12:36:11.077426 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select vault.links', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:36:11.172332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '54810196-94d2-44ed-a2f8-ae26f2fb9962', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff80a15210>]}
[0m12:36:11.204319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '54810196-94d2-44ed-a2f8-ae26f2fb9962', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e754450>]}
[0m12:36:11.205115 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m12:36:11.241201 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m12:36:11.306246 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:36:11.306783 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:36:11.325801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '54810196-94d2-44ed-a2f8-ae26f2fb9962', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7dd30910>]}
[0m12:36:11.372612 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:11.374073 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:11.384915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '54810196-94d2-44ed-a2f8-ae26f2fb9962', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e0d0e90>]}
[0m12:36:11.385359 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m12:36:11.385664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54810196-94d2-44ed-a2f8-ae26f2fb9962', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7dcc9cd0>]}
[0m12:36:11.386587 [info ] [MainThread]: 
[0m12:36:11.386926 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:36:11.387209 [info ] [MainThread]: 
[0m12:36:11.387605 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:36:11.388278 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:36:11.394400 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:11.643514 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:36:11.644893 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:11.655428 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m12:36:11.659113 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m12:36:11.661658 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:11.663882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54810196-94d2-44ed-a2f8-ae26f2fb9962', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff64753fd0>]}
[0m12:36:11.666388 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.link_product_deal
[0m12:36:11.666859 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `edw`.`link_product_deal` ................... [RUN]
[0m12:36:11.667283 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.link_product_deal)
[0m12:36:11.667664 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.link_product_deal
[0m12:36:11.675485 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.link_product_deal"
[0m12:36:11.676703 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.link_product_deal
[0m12:36:11.705002 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

    select name, type from system.columns where table = 'link_product_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m12:36:11.707267 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:11.709283 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.link_product_deal"
[0m12:36:11.710468 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

        insert into `edw`.`link_product_deal`
        ("product_deal_hash_key", "product_hash_key", "deal_hash_key", "load_date", "record_source")

SELECT DISTINCT
    product_deal_hash_key,
    product_hash_key,
    deal_hash_key,
    load_date,
    record_source
FROM `edw`.`stg_product_deals`
WHERE product_hash_key IS NOT NULL
  AND deal_hash_key IS NOT NULL


AND product_deal_hash_key NOT IN (
    SELECT product_deal_hash_key
    FROM `edw`.`link_product_deal`
)

      ...
[0m12:36:11.715319 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:11.726256 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54810196-94d2-44ed-a2f8-ae26f2fb9962', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff5b2270d0>]}
[0m12:36:11.726883 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model `edw`.`link_product_deal` .............. [[32mOK[0m in 0.06s]
[0m12:36:11.727342 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.link_product_deal
[0m12:36:11.728306 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:36:11.728625 [debug] [MainThread]: Connection 'model.clickhouse_edw.link_product_deal' was left open.
[0m12:36:11.728946 [debug] [MainThread]: On model.clickhouse_edw.link_product_deal: Close
[0m12:36:11.729264 [info ] [MainThread]: 
[0m12:36:11.729584 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m12:36:11.730057 [debug] [MainThread]: Command end result
[0m12:36:11.790031 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:11.791507 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:11.795066 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m12:36:11.795373 [info ] [MainThread]: 
[0m12:36:11.795718 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:36:11.796007 [info ] [MainThread]: 
[0m12:36:11.796331 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m12:36:11.797026 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.75099057, "process_in_blocks": "0", "process_kernel_time": 0.158656, "process_mem_max_rss": "186452", "process_out_blocks": "2125", "process_user_time": 2.129392}
[0m12:36:11.797413 [debug] [MainThread]: Command `dbt run` succeeded at 12:36:11.797360 after 0.75 seconds
[0m12:36:11.797743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e6aeb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff824bc810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff824f98d0>]}
[0m12:36:11.798050 [debug] [MainThread]: Flushing usage events
[0m12:36:12.884220 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:36:14.280081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99e75c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99e751d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99e759d0>]}


============================== 12:36:14.283958 | c42d4b70-d0cd-402b-910a-2ac0a9fcee68 ==============================
[0m12:36:14.283958 [info ] [MainThread]: Running with dbt=1.10.6
[0m12:36:14.284443 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select vault.satellites', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:36:14.371020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99cb7f10>]}
[0m12:36:14.398630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9a4e4390>]}
[0m12:36:14.399232 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m12:36:14.433584 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m12:36:14.494538 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:36:14.495045 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:36:14.514686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff999940d0>]}
[0m12:36:14.558245 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:14.559612 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:14.570784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99e3d210>]}
[0m12:36:14.571257 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m12:36:14.571606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99f08f50>]}
[0m12:36:14.572630 [info ] [MainThread]: 
[0m12:36:14.572955 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:36:14.573239 [info ] [MainThread]: 
[0m12:36:14.573644 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:36:14.576940 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:36:14.583159 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:14.836734 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:36:14.837932 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:14.845409 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m12:36:14.849155 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m12:36:14.851426 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:14.853078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91d9d910>]}
[0m12:36:14.855426 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_current
[0m12:36:14.855875 [info ] [Thread-1 (]: 1 of 3 START sql incremental model `edw`.`sat_product_current` ................. [RUN]
[0m12:36:14.856290 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.sat_product_current)
[0m12:36:14.856617 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_current
[0m12:36:14.864376 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_current"
[0m12:36:14.865756 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_current
[0m12:36:14.892874 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

    select name, type from system.columns where table = 'sat_product_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m12:36:14.895056 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:14.897184 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_current"
[0m12:36:14.898347 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

        insert into `edw`.`sat_product_current`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source")

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE (product_hash_key, product_hash_diff, load_date) NOT IN (
    SELECT product_hash_key, product_hash_diff, load_date
    FROM `edw`.`sat_product_current`
)

      ...
[0m12:36:14.918414 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:36:14.929095 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff770bb950>]}
[0m12:36:14.929695 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model `edw`.`sat_product_current` ............ [[32mOK[0m in 0.07s]
[0m12:36:14.930159 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_current
[0m12:36:14.930514 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_deal_current
[0m12:36:14.931073 [info ] [Thread-1 (]: 2 of 3 START sql incremental model `edw`.`sat_product_deal_current` ............ [RUN]
[0m12:36:14.931531 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_current, now model.clickhouse_edw.sat_product_deal_current)
[0m12:36:14.931862 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_deal_current
[0m12:36:14.934102 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_deal_current"
[0m12:36:14.935008 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_deal_current
[0m12:36:14.954346 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

            

    
        create table `edw`.`sat_product_deal_current`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


          )
        
        ...
[0m12:36:14.959167 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:14.964557 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

    select name, type from system.columns where table = 'sat_product_deal_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m12:36:14.966506 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:14.967686 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_deal_current"
[0m12:36:14.968646 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

        
  
    
    
    
        
         


        insert into `edw`.`sat_product_deal_current`
        ("product_deal_hash_key", "revenue_hash_diff", "revenue", "month", "quantity", "load_date", "record_source")

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


  
    ...
[0m12:36:14.970971 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:14.973996 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99e3d310>]}
[0m12:36:14.974485 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model `edw`.`sat_product_deal_current` ....... [[32mOK[0m in 0.04s]
[0m12:36:14.974881 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_deal_current
[0m12:36:14.975253 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_history
[0m12:36:14.975650 [info ] [Thread-1 (]: 3 of 3 START sql table model `edw`.`sat_product_history` ....................... [RUN]
[0m12:36:14.975996 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_deal_current, now model.clickhouse_edw.sat_product_history)
[0m12:36:14.976301 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_history
[0m12:36:14.979059 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_history"
[0m12:36:14.979919 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_history
[0m12:36:15.023539 [debug] [Thread-1 (]: Creating new relation sat_product_history
[0m12:36:15.024618 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

            

    
        create table `edw`.`sat_product_history`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
          )
        
        ...
[0m12:36:15.032537 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:36:15.034434 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

    select name, type from system.columns where table = 'sat_product_history'
    
      and database = 'edw'
    
    order by position
  ...
[0m12:36:15.036227 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:15.037600 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_history"
[0m12:36:15.038859 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

  
    
    
    
        
         


        insert into `edw`.`sat_product_history`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source", "load_end_date", "is_current")

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
  ...
[0m12:36:15.045682 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:36:15.047044 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

        OPTIMIZE TABLE `edw`.`sat_product_history` FINAL
      ...
[0m12:36:15.048805 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:36:15.049727 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42d4b70-d0cd-402b-910a-2ac0a9fcee68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff76fd7610>]}
[0m12:36:15.050245 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `edw`.`sat_product_history` .................. [[32mOK[0m in 0.07s]
[0m12:36:15.050784 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_history
[0m12:36:15.051704 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:36:15.052001 [debug] [MainThread]: Connection 'model.clickhouse_edw.sat_product_history' was left open.
[0m12:36:15.052301 [debug] [MainThread]: On model.clickhouse_edw.sat_product_history: Close
[0m12:36:15.052687 [info ] [MainThread]: 
[0m12:36:15.052981 [info ] [MainThread]: Finished running 2 incremental models, 1 table model in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m12:36:15.053544 [debug] [MainThread]: Command end result
[0m12:36:15.074393 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:15.075754 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:15.079252 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m12:36:15.079549 [info ] [MainThread]: 
[0m12:36:15.079869 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:36:15.080181 [info ] [MainThread]: 
[0m12:36:15.080481 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m12:36:15.081129 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8280511, "process_in_blocks": "0", "process_kernel_time": 0.138803, "process_mem_max_rss": "186812", "process_out_blocks": "2166", "process_user_time": 2.247813}
[0m12:36:15.081516 [debug] [MainThread]: Command `dbt run` succeeded at 12:36:15.081463 after 0.83 seconds
[0m12:36:15.081826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e358410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e29c790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e2d9810>]}
[0m12:36:15.082198 [debug] [MainThread]: Flushing usage events
[0m12:36:16.435946 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:36:17.819508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3c57ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3c57dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3c55e90>]}


============================== 12:36:17.823536 | ec1b5ca0-19f8-47d1-a64c-2cfb6ef66ab2 ==============================
[0m12:36:17.823536 [info ] [MainThread]: Running with dbt=1.10.6
[0m12:36:17.824030 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:36:17.923434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec1b5ca0-19f8-47d1-a64c-2cfb6ef66ab2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3ac5890>]}
[0m12:36:17.954319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec1b5ca0-19f8-47d1-a64c-2cfb6ef66ab2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3b173d0>]}
[0m12:36:17.955236 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m12:36:17.997685 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m12:36:18.083864 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:36:18.084551 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:36:18.108478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec1b5ca0-19f8-47d1-a64c-2cfb6ef66ab2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3578650>]}
[0m12:36:18.163979 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:18.165969 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:18.186501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec1b5ca0-19f8-47d1-a64c-2cfb6ef66ab2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb339bed0>]}
[0m12:36:18.187008 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m12:36:18.187338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec1b5ca0-19f8-47d1-a64c-2cfb6ef66ab2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb36a4250>]}
[0m12:36:18.188351 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m12:36:18.189641 [debug] [MainThread]: Command end result
[0m12:36:18.211735 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:36:18.213399 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:36:18.215941 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m12:36:18.216658 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.42693013, "process_in_blocks": "0", "process_kernel_time": 0.108422, "process_mem_max_rss": "109716", "process_out_blocks": "2112", "process_user_time": 1.388404}
[0m12:36:18.217090 [debug] [MainThread]: Command `dbt test` succeeded at 12:36:18.217022 after 0.43 seconds
[0m12:36:18.217406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7f30410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7e74590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7ead590>]}
[0m12:36:18.217713 [debug] [MainThread]: Flushing usage events
[0m12:36:19.312965 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:48:58.556616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8b250d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8951ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8950210>]}


============================== 13:48:58.560417 | 652a0c30-577a-415f-8fa2-2f167af9eefe ==============================
[0m13:48:58.560417 [info ] [MainThread]: Running with dbt=1.10.6
[0m13:48:58.560852 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt debug', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:48:58.567019 [info ] [MainThread]: dbt version: 1.10.6
[0m13:48:58.567376 [info ] [MainThread]: python version: 3.11.5
[0m13:48:58.567664 [info ] [MainThread]: python path: /usr/local/bin/python
[0m13:48:58.567942 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.31
[0m13:48:58.600820 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt
[0m13:48:58.601258 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt/profiles.yml
[0m13:48:58.601587 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt/dbt_project.yml
[0m13:48:58.602070 [info ] [MainThread]: adapter type: clickhouse
[0m13:48:58.602402 [info ] [MainThread]: adapter version: 1.9.2
[0m13:48:58.649155 [info ] [MainThread]: Configuration:
[0m13:48:58.649597 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m13:48:58.649928 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m13:48:58.650231 [info ] [MainThread]: Required dependencies:
[0m13:48:58.650541 [debug] [MainThread]: Executing "git --help"
[0m13:48:58.651340 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m13:48:58.651633 [info ] [MainThread]: Connection:
[0m13:48:58.651993 [info ] [MainThread]:   driver: None
[0m13:48:58.652279 [info ] [MainThread]:   host: clickhouse-edw
[0m13:48:58.652549 [info ] [MainThread]:   port: 8123
[0m13:48:58.652829 [info ] [MainThread]:   user: default
[0m13:48:58.653105 [info ] [MainThread]:   schema: edw
[0m13:48:58.653383 [info ] [MainThread]:   retries: 1
[0m13:48:58.653648 [info ] [MainThread]:   cluster: None
[0m13:48:58.653929 [info ] [MainThread]:   database_engine: None
[0m13:48:58.654202 [info ] [MainThread]:   cluster_mode: False
[0m13:48:58.654559 [info ] [MainThread]:   secure: False
[0m13:48:58.654854 [info ] [MainThread]:   verify: False
[0m13:48:58.655124 [info ] [MainThread]:   client_cert: None
[0m13:48:58.655402 [info ] [MainThread]:   client_cert_key: None
[0m13:48:58.655668 [info ] [MainThread]:   connect_timeout: 10
[0m13:48:58.655933 [info ] [MainThread]:   send_receive_timeout: 300
[0m13:48:58.656191 [info ] [MainThread]:   sync_request_timeout: 5
[0m13:48:58.656447 [info ] [MainThread]:   compress_block_size: 1048576
[0m13:48:58.656704 [info ] [MainThread]:   compression: 
[0m13:48:58.656979 [info ] [MainThread]:   check_exchange: True
[0m13:48:58.657254 [info ] [MainThread]:   custom_settings: {'async_insert': 1, 'wait_for_async_insert': 1}
[0m13:48:58.657513 [info ] [MainThread]:   use_lw_deletes: False
[0m13:48:58.657783 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m13:48:58.658048 [info ] [MainThread]:   tcp_keepalive: False
[0m13:48:58.658392 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m13:48:58.694017 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m13:48:58.694428 [debug] [MainThread]: Opening a new connection, currently in state init
[0m13:48:58.971733 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m13:48:58.973211 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:48:58.983336 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m13:48:58.983800 [info ] [MainThread]: [31m1 check failed:[0m
[0m13:48:58.984130 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m13:48:58.984882 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.45524508, "process_in_blocks": "28808", "process_kernel_time": 0.192807, "process_mem_max_rss": "176976", "process_out_blocks": "1409", "process_user_time": 2.00063}
[0m13:48:58.985313 [debug] [MainThread]: Command `dbt debug` failed at 13:48:58.985260 after 0.46 seconds
[0m13:48:58.985626 [debug] [MainThread]: Connection 'debug' was left open.
[0m13:48:58.985967 [debug] [MainThread]: On debug: Close
[0m13:48:58.986298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8b271d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbcdf43d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb878ac50>]}
[0m13:48:58.986591 [debug] [MainThread]: Flushing usage events
[0m13:49:01.630711 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:49:02.872264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb75c1810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7953790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb75c2090>]}


============================== 13:49:02.876046 | b955c71e-2cba-4f90-ae7c-828f7cd6bed4 ==============================
[0m13:49:02.876046 [info ] [MainThread]: Running with dbt=1.10.6
[0m13:49:02.876500 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select staging', 'send_anonymous_usage_stats': 'True'}
[0m13:49:02.981207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7c046d0>]}
[0m13:49:03.009617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7bdc4d0>]}
[0m13:49:03.010314 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m13:49:03.048142 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m13:49:03.128259 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:49:03.128741 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:49:03.148565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb707b510>]}
[0m13:49:03.197768 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:03.200470 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:03.213161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7518290>]}
[0m13:49:03.213609 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m13:49:03.213956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7088350>]}
[0m13:49:03.214889 [info ] [MainThread]: 
[0m13:49:03.215213 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:03.215493 [info ] [MainThread]: 
[0m13:49:03.215916 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:49:03.219459 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:49:03.225846 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:03.530476 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:49:03.532678 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:03.545316 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m13:49:03.550263 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m13:49:03.558879 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m13:49:03.561638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb752a050>]}
[0m13:49:03.566589 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product
[0m13:49:03.567516 [info ] [Thread-1 (]: 1 of 2 START sql view model `edw`.`stg_product` ................................ [RUN]
[0m13:49:03.568247 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.stg_product)
[0m13:49:03.568780 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product
[0m13:49:03.575777 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product"
[0m13:49:03.578083 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product
[0m13:49:03.588590 [debug] [Thread-1 (]: Creating new relation stg_product
[0m13:49:03.598008 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product"
[0m13:49:03.600415 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product"} */


  create or replace view `edw`.`stg_product` 
  
    
  
  
    
    
  as (
    

WITH source_data AS (
    SELECT DISTINCT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        deal_name,
        load_date,
        record_source,
        product_hash_key,
        deal_hash_key,
        product_deal_hash_key,
        product_hash_diff
    FROM `edw`.`stg_products`
),

normalized_products AS (
    SELECT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        product_hash_key,
        product_hash_diff,
        max(load_date) AS load_date,
        max(record_source) AS record_source
    FROM source_data
    GROUP BY
        product_base_id, product_name, product_description,
        category, brand, product_rating, product_image,
        shop_name, shop_link, revenue, month, price, quantity,
        product_hash_key, product_hash_diff
)

SELECT * FROM normalized_products
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m13:49:03.604998 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:03.617224 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff986fc450>]}
[0m13:49:03.618244 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `edw`.`stg_product` ........................... [[32mOK[0m in 0.05s]
[0m13:49:03.618940 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product
[0m13:49:03.619468 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product_deals
[0m13:49:03.620299 [info ] [Thread-1 (]: 2 of 2 START sql view model `edw`.`stg_product_deals` .......................... [RUN]
[0m13:49:03.621017 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.stg_product, now model.clickhouse_edw.stg_product_deals)
[0m13:49:03.621523 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product_deals
[0m13:49:03.623974 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product_deals"
[0m13:49:03.625204 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product_deals
[0m13:49:03.627687 [debug] [Thread-1 (]: Creating new relation stg_product_deals
[0m13:49:03.629025 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product_deals"
[0m13:49:03.630245 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product_deals: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product_deals"} */


  create or replace view `edw`.`stg_product_deals` 
  
    
  
  
    
    
  as (
    

SELECT DISTINCT
    product_base_id,
    deal_name,
    product_hash_key,
    deal_hash_key,
    product_deal_hash_key,
    max(load_date) AS load_date,
    max(record_source) AS record_source
FROM `edw`.`stg_products`
GROUP BY
    product_base_id, deal_name,
    product_hash_key, deal_hash_key, product_deal_hash_key
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m13:49:03.633061 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:03.634836 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b955c71e-2cba-4f90-ae7c-828f7cd6bed4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb7548a90>]}
[0m13:49:03.635553 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `edw`.`stg_product_deals` ..................... [[32mOK[0m in 0.01s]
[0m13:49:03.636148 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product_deals
[0m13:49:03.637472 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:49:03.637960 [debug] [MainThread]: Connection 'model.clickhouse_edw.stg_product_deals' was left open.
[0m13:49:03.638407 [debug] [MainThread]: On model.clickhouse_edw.stg_product_deals: Close
[0m13:49:03.638888 [info ] [MainThread]: 
[0m13:49:03.639235 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.42 seconds (0.42s).
[0m13:49:03.639855 [debug] [MainThread]: Command end result
[0m13:49:03.710661 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:03.712331 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:03.716584 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m13:49:03.716939 [info ] [MainThread]: 
[0m13:49:03.717459 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:49:03.717874 [info ] [MainThread]: 
[0m13:49:03.718362 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m13:49:03.719203 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.87395513, "process_in_blocks": "2800", "process_kernel_time": 0.157186, "process_mem_max_rss": "185336", "process_out_blocks": "2142", "process_user_time": 2.228643}
[0m13:49:03.719633 [debug] [MainThread]: Command `dbt run` succeeded at 13:49:03.719582 after 0.87 seconds
[0m13:49:03.720024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbb9ac3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbb8f05d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbb92d890>]}
[0m13:49:03.720386 [debug] [MainThread]: Flushing usage events
[0m13:49:05.267711 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:49:06.551813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88a75e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88a75b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88a75f90>]}


============================== 13:49:06.555358 | 1a8fd9c4-bdee-467f-a235-797162ae3632 ==============================
[0m13:49:06.555358 [info ] [MainThread]: Running with dbt=1.10.6
[0m13:49:06.555815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select vault.hubs', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:49:06.643301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88b12e10>]}
[0m13:49:06.676656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff890e4490>]}
[0m13:49:06.677423 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m13:49:06.711236 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m13:49:06.772461 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:49:06.772974 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:49:06.792476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88877cd0>]}
[0m13:49:06.843307 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:06.845121 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:06.856878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a8ad2d0>]}
[0m13:49:06.857392 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m13:49:06.857816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88594250>]}
[0m13:49:06.859102 [info ] [MainThread]: 
[0m13:49:06.859551 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:06.859925 [info ] [MainThread]: 
[0m13:49:06.860384 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:49:06.863936 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:49:06.870584 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:07.141527 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:49:07.143059 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:07.152442 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m13:49:07.156660 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m13:49:07.159817 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:07.161640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff88594250>]}
[0m13:49:07.164525 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_deal
[0m13:49:07.165046 [info ] [Thread-1 (]: 1 of 2 START sql incremental model `edw`.`hub_deal` ............................ [RUN]
[0m13:49:07.165518 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.hub_deal)
[0m13:49:07.166089 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_deal
[0m13:49:07.174271 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_deal"
[0m13:49:07.175742 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_deal
[0m13:49:07.204852 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

    select name, type from system.columns where table = 'hub_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m13:49:07.208268 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:07.210530 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_deal"
[0m13:49:07.211959 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

        insert into `edw`.`hub_deal`
        ("deal_hash_key", "deal_business_key", "load_date", "record_source")

WITH deal_data AS (
    SELECT DISTINCT
        deal_name,
        deal_hash_key,
        load_date,
        record_source
    FROM `edw`.`stg_product_deals`
    WHERE deal_name IS NOT NULL
)

SELECT
    deal_hash_key,
    deal_name AS deal_business_key,
    load_date,
    record_source
FROM deal_data


WHERE deal_hash_key NOT IN (
    SELECT deal_hash_key
    FROM `edw`.`hub_deal`
)

      ...
[0m13:49:07.220773 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m13:49:07.232028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff69c9f950>]}
[0m13:49:07.232808 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model `edw`.`hub_deal` ....................... [[32mOK[0m in 0.07s]
[0m13:49:07.233406 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_deal
[0m13:49:07.233837 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_product
[0m13:49:07.234303 [info ] [Thread-1 (]: 2 of 2 START sql incremental model `edw`.`hub_product` ......................... [RUN]
[0m13:49:07.234720 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.hub_deal, now model.clickhouse_edw.hub_product)
[0m13:49:07.235133 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_product
[0m13:49:07.237624 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_product"
[0m13:49:07.238823 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_product
[0m13:49:07.242087 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

    select name, type from system.columns where table = 'hub_product'
    
      and database = 'edw'
    
    order by position
  ...
[0m13:49:07.244352 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:07.245371 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_product"
[0m13:49:07.246503 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

        insert into `edw`.`hub_product`
        ("product_hash_key", "product_business_key", "load_date", "record_source")

SELECT DISTINCT
    product_hash_key,
    product_base_id AS product_business_key,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE product_hash_key NOT IN (
    SELECT product_hash_key
    FROM `edw`.`hub_product`
)

      ...
[0m13:49:07.254292 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m13:49:07.255842 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1a8fd9c4-bdee-467f-a235-797162ae3632', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6a786d10>]}
[0m13:49:07.256374 [info ] [Thread-1 (]: 2 of 2 OK created sql incremental model `edw`.`hub_product` .................... [[32mOK[0m in 0.02s]
[0m13:49:07.256822 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_product
[0m13:49:07.257837 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:49:07.258190 [debug] [MainThread]: Connection 'model.clickhouse_edw.hub_product' was left open.
[0m13:49:07.258502 [debug] [MainThread]: On model.clickhouse_edw.hub_product: Close
[0m13:49:07.258874 [info ] [MainThread]: 
[0m13:49:07.259185 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 0.40 seconds (0.40s).
[0m13:49:07.259682 [debug] [MainThread]: Command end result
[0m13:49:07.320043 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:07.321614 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:07.325293 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m13:49:07.325644 [info ] [MainThread]: 
[0m13:49:07.326019 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:49:07.326346 [info ] [MainThread]: 
[0m13:49:07.326689 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m13:49:07.327435 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8021823, "process_in_blocks": "0", "process_kernel_time": 0.12291, "process_mem_max_rss": "186496", "process_out_blocks": "2133", "process_user_time": 2.253701}
[0m13:49:07.327862 [debug] [MainThread]: Command `dbt run` succeeded at 13:49:07.327804 after 0.80 seconds
[0m13:49:07.328200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ceac350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ce589d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ce2d8d0>]}
[0m13:49:07.328517 [debug] [MainThread]: Flushing usage events
[0m13:49:08.579020 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:49:09.829896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5b14990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5b15310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5b15810>]}


============================== 13:49:09.833827 | df581f7e-61a4-4168-a51a-9415f2221f9d ==============================
[0m13:49:09.833827 [info ] [MainThread]: Running with dbt=1.10.6
[0m13:49:09.834298 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select vault.links', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:49:09.922021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'df581f7e-61a4-4168-a51a-9415f2221f9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5754d50>]}
[0m13:49:09.951333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'df581f7e-61a4-4168-a51a-9415f2221f9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6818550>]}
[0m13:49:09.952136 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m13:49:09.987635 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m13:49:10.051688 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:49:10.052164 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:49:10.072269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'df581f7e-61a4-4168-a51a-9415f2221f9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5617510>]}
[0m13:49:10.116346 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:10.117742 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:10.128073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'df581f7e-61a4-4168-a51a-9415f2221f9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa54e7e90>]}
[0m13:49:10.128509 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m13:49:10.128869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df581f7e-61a4-4168-a51a-9415f2221f9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5480890>]}
[0m13:49:10.129806 [info ] [MainThread]: 
[0m13:49:10.130143 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:10.130417 [info ] [MainThread]: 
[0m13:49:10.130842 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:49:10.131494 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:49:10.137538 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:10.388776 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:49:10.390090 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:10.400361 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m13:49:10.403980 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m13:49:10.406279 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:10.408003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'df581f7e-61a4-4168-a51a-9415f2221f9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa5561090>]}
[0m13:49:10.410318 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.link_product_deal
[0m13:49:10.410745 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `edw`.`link_product_deal` ................... [RUN]
[0m13:49:10.411139 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.link_product_deal)
[0m13:49:10.411470 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.link_product_deal
[0m13:49:10.419038 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.link_product_deal"
[0m13:49:10.420191 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.link_product_deal
[0m13:49:10.446387 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

    select name, type from system.columns where table = 'link_product_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m13:49:10.448353 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:10.450227 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.link_product_deal"
[0m13:49:10.451307 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

        insert into `edw`.`link_product_deal`
        ("product_deal_hash_key", "product_hash_key", "deal_hash_key", "load_date", "record_source")

SELECT DISTINCT
    product_deal_hash_key,
    product_hash_key,
    deal_hash_key,
    load_date,
    record_source
FROM `edw`.`stg_product_deals`
WHERE product_hash_key IS NOT NULL
  AND deal_hash_key IS NOT NULL


AND product_deal_hash_key NOT IN (
    SELECT product_deal_hash_key
    FROM `edw`.`link_product_deal`
)

      ...
[0m13:49:10.455812 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:10.466276 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df581f7e-61a4-4168-a51a-9415f2221f9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82a23dd0>]}
[0m13:49:10.466875 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model `edw`.`link_product_deal` .............. [[32mOK[0m in 0.05s]
[0m13:49:10.467332 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.link_product_deal
[0m13:49:10.468378 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:49:10.468780 [debug] [MainThread]: Connection 'model.clickhouse_edw.link_product_deal' was left open.
[0m13:49:10.469095 [debug] [MainThread]: On model.clickhouse_edw.link_product_deal: Close
[0m13:49:10.469427 [info ] [MainThread]: 
[0m13:49:10.469764 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.34 seconds (0.34s).
[0m13:49:10.470242 [debug] [MainThread]: Command end result
[0m13:49:10.528000 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:10.529525 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:10.533118 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m13:49:10.533437 [info ] [MainThread]: 
[0m13:49:10.533813 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:49:10.534116 [info ] [MainThread]: 
[0m13:49:10.534406 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m13:49:10.535132 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.73346794, "process_in_blocks": "0", "process_kernel_time": 0.122867, "process_mem_max_rss": "186604", "process_out_blocks": "2125", "process_user_time": 2.167669}
[0m13:49:10.535530 [debug] [MainThread]: Command `dbt run` succeeded at 13:49:10.535479 after 0.73 seconds
[0m13:49:10.535853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9c2c5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa52f6410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa9c69890>]}
[0m13:49:10.536159 [debug] [MainThread]: Flushing usage events
[0m13:49:11.623663 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:49:12.995516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96c75c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff97053390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff97053590>]}


============================== 13:49:12.999443 | 8310b5f3-9357-4380-a13d-457a1ef7c049 ==============================
[0m13:49:12.999443 [info ] [MainThread]: Running with dbt=1.10.6
[0m13:49:13.000044 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select vault.satellites', 'send_anonymous_usage_stats': 'True'}
[0m13:49:13.097670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96bf2fd0>]}
[0m13:49:13.130224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff972e4490>]}
[0m13:49:13.131173 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m13:49:13.167863 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m13:49:13.233400 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:49:13.233905 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:49:13.252866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96a76fd0>]}
[0m13:49:13.300509 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:13.302183 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:13.313447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96b240d0>]}
[0m13:49:13.313940 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m13:49:13.314348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96ae4690>]}
[0m13:49:13.315374 [info ] [MainThread]: 
[0m13:49:13.315701 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:49:13.316010 [info ] [MainThread]: 
[0m13:49:13.316432 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m13:49:13.319781 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m13:49:13.326131 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:49:13.608059 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m13:49:13.609597 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:13.618395 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m13:49:13.622862 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m13:49:13.625683 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:13.627492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff940fa290>]}
[0m13:49:13.630343 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_current
[0m13:49:13.630858 [info ] [Thread-1 (]: 1 of 3 START sql incremental model `edw`.`sat_product_current` ................. [RUN]
[0m13:49:13.631418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.sat_product_current)
[0m13:49:13.631855 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_current
[0m13:49:13.640508 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_current"
[0m13:49:13.641851 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_current
[0m13:49:13.670806 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

    select name, type from system.columns where table = 'sat_product_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m13:49:13.673332 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:13.675554 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_current"
[0m13:49:13.676950 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

        insert into `edw`.`sat_product_current`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source")

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE (product_hash_key, product_hash_diff, load_date) NOT IN (
    SELECT product_hash_key, product_hash_diff, load_date
    FROM `edw`.`sat_product_current`
)

      ...
[0m13:49:13.696901 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m13:49:13.708460 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96691650>]}
[0m13:49:13.709157 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model `edw`.`sat_product_current` ............ [[32mOK[0m in 0.08s]
[0m13:49:13.709669 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_current
[0m13:49:13.710048 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_deal_current
[0m13:49:13.710554 [info ] [Thread-1 (]: 2 of 3 START sql incremental model `edw`.`sat_product_deal_current` ............ [RUN]
[0m13:49:13.710992 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_current, now model.clickhouse_edw.sat_product_deal_current)
[0m13:49:13.711326 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_deal_current
[0m13:49:13.713999 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_deal_current"
[0m13:49:13.718831 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_deal_current
[0m13:49:13.737932 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

            

    
        create table `edw`.`sat_product_deal_current`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


          )
        
        ...
[0m13:49:13.743778 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m13:49:13.749456 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

    select name, type from system.columns where table = 'sat_product_deal_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m13:49:13.751879 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:13.753215 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_deal_current"
[0m13:49:13.754305 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

        
  
    
    
    
        
         


        insert into `edw`.`sat_product_deal_current`
        ("product_deal_hash_key", "revenue_hash_diff", "revenue", "month", "quantity", "load_date", "record_source")

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


  
    ...
[0m13:49:13.756940 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:13.760408 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff967950d0>]}
[0m13:49:13.760987 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model `edw`.`sat_product_deal_current` ....... [[32mOK[0m in 0.05s]
[0m13:49:13.761453 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_deal_current
[0m13:49:13.761842 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_history
[0m13:49:13.762346 [info ] [Thread-1 (]: 3 of 3 START sql table model `edw`.`sat_product_history` ....................... [RUN]
[0m13:49:13.762792 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_deal_current, now model.clickhouse_edw.sat_product_history)
[0m13:49:13.763157 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_history
[0m13:49:13.766349 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_history"
[0m13:49:13.767479 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_history
[0m13:49:13.815050 [debug] [Thread-1 (]: Creating new relation sat_product_history
[0m13:49:13.816171 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

            

    
        create table `edw`.`sat_product_history`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
          )
        
        ...
[0m13:49:13.825858 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m13:49:13.828065 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

    select name, type from system.columns where table = 'sat_product_history'
    
      and database = 'edw'
    
    order by position
  ...
[0m13:49:13.830196 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:13.831699 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_history"
[0m13:49:13.832827 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

  
    
    
    
        
         


        insert into `edw`.`sat_product_history`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source", "load_end_date", "is_current")

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
  ...
[0m13:49:13.841049 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m13:49:13.842585 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

        OPTIMIZE TABLE `edw`.`sat_product_history` FINAL
      ...
[0m13:49:13.844853 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m13:49:13.845990 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8310b5f3-9357-4380-a13d-457a1ef7c049', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff73ca6e90>]}
[0m13:49:13.846484 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `edw`.`sat_product_history` .................. [[32mOK[0m in 0.08s]
[0m13:49:13.846924 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_history
[0m13:49:13.847873 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:49:13.848171 [debug] [MainThread]: Connection 'model.clickhouse_edw.sat_product_history' was left open.
[0m13:49:13.848446 [debug] [MainThread]: On model.clickhouse_edw.sat_product_history: Close
[0m13:49:13.848808 [info ] [MainThread]: 
[0m13:49:13.849111 [info ] [MainThread]: Finished running 2 incremental models, 1 table model in 0 hours 0 minutes and 0.53 seconds (0.53s).
[0m13:49:13.849686 [debug] [MainThread]: Command end result
[0m13:49:13.871236 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:13.872643 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:13.876336 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m13:49:13.876802 [info ] [MainThread]: 
[0m13:49:13.877162 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:49:13.877461 [info ] [MainThread]: 
[0m13:49:13.877802 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m13:49:13.878514 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.91429293, "process_in_blocks": "0", "process_kernel_time": 0.155254, "process_mem_max_rss": "186628", "process_out_blocks": "2166", "process_user_time": 2.393919}
[0m13:49:13.878931 [debug] [MainThread]: Command `dbt run` succeeded at 13:49:13.878881 after 0.91 seconds
[0m13:49:13.879257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9b068350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9710b5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9afe9850>]}
[0m13:49:13.879579 [debug] [MainThread]: Flushing usage events
[0m13:49:15.050030 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:49:16.345013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86247f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86245790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86245050>]}


============================== 13:49:16.348572 | 1af918c1-97ff-42ff-b4a5-63e145162c9c ==============================
[0m13:49:16.348572 [info ] [MainThread]: Running with dbt=1.10.6
[0m13:49:16.349043 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m13:49:16.436080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1af918c1-97ff-42ff-b4a5-63e145162c9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff860b6ad0>]}
[0m13:49:16.464412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1af918c1-97ff-42ff-b4a5-63e145162c9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85ff5c50>]}
[0m13:49:16.465059 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m13:49:16.500901 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m13:49:16.566722 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:49:16.567216 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:49:16.586477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1af918c1-97ff-42ff-b4a5-63e145162c9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85d0ea90>]}
[0m13:49:16.631014 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:16.632483 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:16.649138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1af918c1-97ff-42ff-b4a5-63e145162c9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85984bd0>]}
[0m13:49:16.649758 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m13:49:16.650192 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1af918c1-97ff-42ff-b4a5-63e145162c9c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85e1ab10>]}
[0m13:49:16.651283 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m13:49:16.652506 [debug] [MainThread]: Command end result
[0m13:49:16.672434 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m13:49:16.673776 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m13:49:16.675870 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m13:49:16.676517 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.3585046, "process_in_blocks": "1224", "process_kernel_time": 0.100683, "process_mem_max_rss": "109572", "process_out_blocks": "2112", "process_user_time": 1.250076}
[0m13:49:16.676916 [debug] [MainThread]: Command `dbt test` succeeded at 13:49:16.676864 after 0.36 seconds
[0m13:49:16.677271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86075690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a4743d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a420690>]}
[0m13:49:16.677598 [debug] [MainThread]: Flushing usage events
[0m13:49:18.122347 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:11:29.146620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a656c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a656f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a655f10>]}


============================== 14:11:29.150584 | 173232cc-6986-4803-ac09-97b4c526302b ==============================
[0m14:11:29.150584 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:11:29.151190 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:11:29.155844 [info ] [MainThread]: dbt version: 1.10.6
[0m14:11:29.156433 [info ] [MainThread]: python version: 3.11.5
[0m14:11:29.156910 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:11:29.157324 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.31
[0m14:11:29.191697 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt
[0m14:11:29.192279 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt/profiles.yml
[0m14:11:29.192686 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt/dbt_project.yml
[0m14:11:29.193380 [info ] [MainThread]: adapter type: clickhouse
[0m14:11:29.193913 [info ] [MainThread]: adapter version: 1.9.2
[0m14:11:29.246499 [info ] [MainThread]: Configuration:
[0m14:11:29.247075 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:11:29.247508 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:11:29.247902 [info ] [MainThread]: Required dependencies:
[0m14:11:29.248428 [debug] [MainThread]: Executing "git --help"
[0m14:11:29.249399 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m14:11:29.249773 [info ] [MainThread]: Connection:
[0m14:11:29.250105 [info ] [MainThread]:   driver: None
[0m14:11:29.250439 [info ] [MainThread]:   host: clickhouse-edw
[0m14:11:29.250737 [info ] [MainThread]:   port: 8123
[0m14:11:29.251031 [info ] [MainThread]:   user: default
[0m14:11:29.251327 [info ] [MainThread]:   schema: edw
[0m14:11:29.251674 [info ] [MainThread]:   retries: 1
[0m14:11:29.252009 [info ] [MainThread]:   cluster: None
[0m14:11:29.252482 [info ] [MainThread]:   database_engine: None
[0m14:11:29.252915 [info ] [MainThread]:   cluster_mode: False
[0m14:11:29.253320 [info ] [MainThread]:   secure: False
[0m14:11:29.253653 [info ] [MainThread]:   verify: False
[0m14:11:29.254008 [info ] [MainThread]:   client_cert: None
[0m14:11:29.254348 [info ] [MainThread]:   client_cert_key: None
[0m14:11:29.254652 [info ] [MainThread]:   connect_timeout: 10
[0m14:11:29.254971 [info ] [MainThread]:   send_receive_timeout: 300
[0m14:11:29.255312 [info ] [MainThread]:   sync_request_timeout: 5
[0m14:11:29.255690 [info ] [MainThread]:   compress_block_size: 1048576
[0m14:11:29.256062 [info ] [MainThread]:   compression: 
[0m14:11:29.256467 [info ] [MainThread]:   check_exchange: True
[0m14:11:29.256791 [info ] [MainThread]:   custom_settings: {'async_insert': 1, 'wait_for_async_insert': 1}
[0m14:11:29.257089 [info ] [MainThread]:   use_lw_deletes: False
[0m14:11:29.257409 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m14:11:29.257704 [info ] [MainThread]:   tcp_keepalive: False
[0m14:11:29.258102 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:11:29.292783 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m14:11:29.293484 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:11:29.621989 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m14:11:29.624211 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:29.634516 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:11:29.635121 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:11:29.635627 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m14:11:29.636542 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.52046716, "process_in_blocks": "0", "process_kernel_time": 0.201729, "process_mem_max_rss": "177752", "process_out_blocks": "1409", "process_user_time": 2.012277}
[0m14:11:29.637160 [debug] [MainThread]: Command `dbt debug` failed at 14:11:29.637063 after 0.52 seconds
[0m14:11:29.637628 [debug] [MainThread]: Connection 'debug' was left open.
[0m14:11:29.638075 [debug] [MainThread]: On debug: Close
[0m14:11:29.638594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e8943d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a422990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff703fc710>]}
[0m14:11:29.639048 [debug] [MainThread]: Flushing usage events
[0m14:11:31.266766 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:11:32.584822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa8977810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa89763d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa8976210>]}


============================== 14:11:32.589338 | 3025ad83-d273-4910-b351-57597da9798b ==============================
[0m14:11:32.589338 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:11:32.589869 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select staging', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:11:32.695624 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa88f9410>]}
[0m14:11:32.728635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa8fe4490>]}
[0m14:11:32.729691 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:11:32.766071 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:11:32.833379 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:32.833898 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:32.853879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa895eb50>]}
[0m14:11:32.899296 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:32.900781 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:32.911748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa84dda90>]}
[0m14:11:32.912230 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:11:32.912568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa898fe10>]}
[0m14:11:32.913502 [info ] [MainThread]: 
[0m14:11:32.913828 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:11:32.914106 [info ] [MainThread]: 
[0m14:11:32.914539 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:11:32.917725 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:11:32.923853 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:33.173669 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:11:33.174944 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:33.182288 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:11:33.186077 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:11:33.188951 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:33.190424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa84deed0>]}
[0m14:11:33.192783 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product
[0m14:11:33.193331 [info ] [Thread-1 (]: 1 of 2 START sql view model `edw`.`stg_product` ................................ [RUN]
[0m14:11:33.193744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.stg_product)
[0m14:11:33.194076 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product
[0m14:11:33.198849 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product"
[0m14:11:33.200534 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product
[0m14:11:33.207710 [debug] [Thread-1 (]: Creating new relation stg_product
[0m14:11:33.214780 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product"
[0m14:11:33.216068 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product"} */


  create or replace view `edw`.`stg_product` 
  
    
  
  
    
    
  as (
    

WITH source_data AS (
    SELECT DISTINCT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        deal_name,
        load_date,
        record_source,
        product_hash_key,
        deal_hash_key,
        product_deal_hash_key,
        product_hash_diff
    FROM `edw`.`stg_products`
),

normalized_products AS (
    SELECT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        product_hash_key,
        product_hash_diff,
        max(load_date) AS load_date,
        max(record_source) AS record_source
    FROM source_data
    GROUP BY
        product_base_id, product_name, product_description,
        category, brand, product_rating, product_image,
        shop_name, shop_link, revenue, month, price, quantity,
        product_hash_key, product_hash_diff
)

SELECT * FROM normalized_products
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m14:11:33.219540 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:33.229941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff98ba2f10>]}
[0m14:11:33.230483 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `edw`.`stg_product` ........................... [[32mOK[0m in 0.04s]
[0m14:11:33.230906 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product
[0m14:11:33.231259 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product_deals
[0m14:11:33.231685 [info ] [Thread-1 (]: 2 of 2 START sql view model `edw`.`stg_product_deals` .......................... [RUN]
[0m14:11:33.232034 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.stg_product, now model.clickhouse_edw.stg_product_deals)
[0m14:11:33.232345 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product_deals
[0m14:11:33.234184 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product_deals"
[0m14:11:33.235041 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product_deals
[0m14:11:33.236475 [debug] [Thread-1 (]: Creating new relation stg_product_deals
[0m14:11:33.237186 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product_deals"
[0m14:11:33.237963 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product_deals: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product_deals"} */


  create or replace view `edw`.`stg_product_deals` 
  
    
  
  
    
    
  as (
    

SELECT DISTINCT
    product_base_id,
    deal_name,
    product_hash_key,
    deal_hash_key,
    product_deal_hash_key,
    max(load_date) AS load_date,
    max(record_source) AS record_source
FROM `edw`.`stg_products`
GROUP BY
    product_base_id, deal_name,
    product_hash_key, deal_hash_key, product_deal_hash_key
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m14:11:33.240113 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:33.241305 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3025ad83-d273-4910-b351-57597da9798b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89bc3110>]}
[0m14:11:33.241738 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `edw`.`stg_product_deals` ..................... [[32mOK[0m in 0.01s]
[0m14:11:33.242130 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product_deals
[0m14:11:33.243095 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:11:33.243406 [debug] [MainThread]: Connection 'model.clickhouse_edw.stg_product_deals' was left open.
[0m14:11:33.243682 [debug] [MainThread]: On model.clickhouse_edw.stg_product_deals: Close
[0m14:11:33.244026 [info ] [MainThread]: 
[0m14:11:33.244329 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.33 seconds (0.33s).
[0m14:11:33.244837 [debug] [MainThread]: Command end result
[0m14:11:33.301635 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:33.303056 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:33.306683 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:11:33.307004 [info ] [MainThread]: 
[0m14:11:33.307353 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:11:33.307642 [info ] [MainThread]: 
[0m14:11:33.307952 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m14:11:33.308656 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.7571001, "process_in_blocks": "0", "process_kernel_time": 0.172669, "process_mem_max_rss": "185216", "process_out_blocks": "2142", "process_user_time": 2.22764}
[0m14:11:33.309053 [debug] [MainThread]: Command `dbt run` succeeded at 14:11:33.309001 after 0.76 seconds
[0m14:11:33.309376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xfffface43c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaccf9910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffacd78390>]}
[0m14:11:33.309729 [debug] [MainThread]: Flushing usage events
[0m14:11:34.527650 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:11:35.745724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d36e090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d36d050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d36d0d0>]}


============================== 14:11:35.749439 | 66f6e2fd-0062-4d12-b43c-c725a16ab240 ==============================
[0m14:11:35.749439 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:11:35.749902 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select vault.hubs', 'send_anonymous_usage_stats': 'True'}
[0m14:11:35.839364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d2a53d0>]}
[0m14:11:35.867889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d988450>]}
[0m14:11:35.868571 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:11:35.904455 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:11:35.967432 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:35.967940 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:35.987881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8cfdea90>]}
[0m14:11:36.035551 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:36.037230 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:36.048756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d2d3910>]}
[0m14:11:36.049247 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:11:36.049588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8da14510>]}
[0m14:11:36.050627 [info ] [MainThread]: 
[0m14:11:36.050979 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:11:36.051279 [info ] [MainThread]: 
[0m14:11:36.051703 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:11:36.054999 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:11:36.061287 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:36.374150 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:11:36.375710 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:36.384949 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:11:36.388782 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:11:36.391421 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:36.393372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8d3a7950>]}
[0m14:11:36.396294 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_deal
[0m14:11:36.396757 [info ] [Thread-1 (]: 1 of 2 START sql incremental model `edw`.`hub_deal` ............................ [RUN]
[0m14:11:36.397315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.hub_deal)
[0m14:11:36.397749 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_deal
[0m14:11:36.406806 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_deal"
[0m14:11:36.408159 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_deal
[0m14:11:36.438214 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

    select name, type from system.columns where table = 'hub_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:11:36.440668 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:36.442914 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_deal"
[0m14:11:36.445057 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

        insert into `edw`.`hub_deal`
        ("deal_hash_key", "deal_business_key", "load_date", "record_source")

WITH deal_data AS (
    SELECT DISTINCT
        deal_name,
        deal_hash_key,
        load_date,
        record_source
    FROM `edw`.`stg_product_deals`
    WHERE deal_name IS NOT NULL
)

SELECT
    deal_hash_key,
    deal_name AS deal_business_key,
    load_date,
    record_source
FROM deal_data


WHERE deal_hash_key NOT IN (
    SELECT deal_hash_key
    FROM `edw`.`hub_deal`
)

      ...
[0m14:11:36.454072 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:11:36.465759 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6e2d4450>]}
[0m14:11:36.466565 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model `edw`.`hub_deal` ....................... [[32mOK[0m in 0.07s]
[0m14:11:36.467230 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_deal
[0m14:11:36.467666 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_product
[0m14:11:36.468158 [info ] [Thread-1 (]: 2 of 2 START sql incremental model `edw`.`hub_product` ......................... [RUN]
[0m14:11:36.468703 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.hub_deal, now model.clickhouse_edw.hub_product)
[0m14:11:36.469035 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_product
[0m14:11:36.471839 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_product"
[0m14:11:36.472842 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_product
[0m14:11:36.476099 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

    select name, type from system.columns where table = 'hub_product'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:11:36.478390 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:36.479409 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_product"
[0m14:11:36.480512 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

        insert into `edw`.`hub_product`
        ("product_hash_key", "product_business_key", "load_date", "record_source")

SELECT DISTINCT
    product_hash_key,
    product_base_id AS product_business_key,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE product_hash_key NOT IN (
    SELECT product_hash_key
    FROM `edw`.`hub_product`
)

      ...
[0m14:11:36.488832 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:11:36.490294 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '66f6e2fd-0062-4d12-b43c-c725a16ab240', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6e2d6250>]}
[0m14:11:36.490822 [info ] [Thread-1 (]: 2 of 2 OK created sql incremental model `edw`.`hub_product` .................... [[32mOK[0m in 0.02s]
[0m14:11:36.491262 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_product
[0m14:11:36.492207 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:11:36.492547 [debug] [MainThread]: Connection 'model.clickhouse_edw.hub_product' was left open.
[0m14:11:36.492893 [debug] [MainThread]: On model.clickhouse_edw.hub_product: Close
[0m14:11:36.493286 [info ] [MainThread]: 
[0m14:11:36.493582 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 0.44 seconds (0.44s).
[0m14:11:36.494093 [debug] [MainThread]: Command end result
[0m14:11:36.555314 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:36.556818 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:36.560535 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:11:36.560888 [info ] [MainThread]: 
[0m14:11:36.561299 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:11:36.561625 [info ] [MainThread]: 
[0m14:11:36.561975 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m14:11:36.562735 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.84359765, "process_in_blocks": "0", "process_kernel_time": 0.126867, "process_mem_max_rss": "186592", "process_out_blocks": "2133", "process_user_time": 2.147763}
[0m14:11:36.563193 [debug] [MainThread]: Command `dbt run` succeeded at 14:11:36.563126 after 0.84 seconds
[0m14:11:36.563534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff916d8250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff916849d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff91659950>]}
[0m14:11:36.563928 [debug] [MainThread]: Flushing usage events
[0m14:11:37.901119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:11:39.157415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1de5c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1de5fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1de61d0>]}


============================== 14:11:39.161040 | e4ef36bb-0584-47a9-88cf-d16940d7641d ==============================
[0m14:11:39.161040 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:11:39.161524 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select vault.links', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:11:39.246481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e4ef36bb-0584-47a9-88cf-d16940d7641d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1b95e50>]}
[0m14:11:39.274331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e4ef36bb-0584-47a9-88cf-d16940d7641d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb22584d0>]}
[0m14:11:39.275022 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:11:39.309252 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:11:39.369576 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:39.370055 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:39.388630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e4ef36bb-0584-47a9-88cf-d16940d7641d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb19053d0>]}
[0m14:11:39.433257 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:39.434638 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:39.444975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e4ef36bb-0584-47a9-88cf-d16940d7641d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1b6e350>]}
[0m14:11:39.445412 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:11:39.445772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4ef36bb-0584-47a9-88cf-d16940d7641d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1c65dd0>]}
[0m14:11:39.446836 [info ] [MainThread]: 
[0m14:11:39.447214 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:11:39.447528 [info ] [MainThread]: 
[0m14:11:39.447939 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:11:39.448603 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:11:39.454652 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:39.697885 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:11:39.699202 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:39.709258 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:11:39.712971 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:11:39.715574 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:39.717301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e4ef36bb-0584-47a9-88cf-d16940d7641d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f51b110>]}
[0m14:11:39.719620 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.link_product_deal
[0m14:11:39.720052 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `edw`.`link_product_deal` ................... [RUN]
[0m14:11:39.720507 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.link_product_deal)
[0m14:11:39.720866 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.link_product_deal
[0m14:11:39.728879 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.link_product_deal"
[0m14:11:39.730050 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.link_product_deal
[0m14:11:39.758105 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

    select name, type from system.columns where table = 'link_product_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:11:39.760322 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:39.762391 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.link_product_deal"
[0m14:11:39.763447 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

        insert into `edw`.`link_product_deal`
        ("product_deal_hash_key", "product_hash_key", "deal_hash_key", "load_date", "record_source")

SELECT DISTINCT
    product_deal_hash_key,
    product_hash_key,
    deal_hash_key,
    load_date,
    record_source
FROM `edw`.`stg_product_deals`
WHERE product_hash_key IS NOT NULL
  AND deal_hash_key IS NOT NULL


AND product_deal_hash_key NOT IN (
    SELECT product_deal_hash_key
    FROM `edw`.`link_product_deal`
)

      ...
[0m14:11:39.768322 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:39.779067 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4ef36bb-0584-47a9-88cf-d16940d7641d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f50b990>]}
[0m14:11:39.779674 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model `edw`.`link_product_deal` .............. [[32mOK[0m in 0.06s]
[0m14:11:39.780149 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.link_product_deal
[0m14:11:39.781092 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:11:39.781494 [debug] [MainThread]: Connection 'model.clickhouse_edw.link_product_deal' was left open.
[0m14:11:39.781808 [debug] [MainThread]: On model.clickhouse_edw.link_product_deal: Close
[0m14:11:39.782160 [info ] [MainThread]: 
[0m14:11:39.782491 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.33 seconds (0.33s).
[0m14:11:39.782955 [debug] [MainThread]: Command end result
[0m14:11:39.839002 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:39.840402 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:39.843767 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:11:39.844072 [info ] [MainThread]: 
[0m14:11:39.844445 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:11:39.844721 [info ] [MainThread]: 
[0m14:11:39.845035 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m14:11:39.845706 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.7150243, "process_in_blocks": "0", "process_kernel_time": 0.149915, "process_mem_max_rss": "186452", "process_out_blocks": "2125", "process_user_time": 2.110815}
[0m14:11:39.846099 [debug] [MainThread]: Command `dbt run` succeeded at 14:11:39.846047 after 0.72 seconds
[0m14:11:39.846435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5fe43d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5f285d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5f65890>]}
[0m14:11:39.846741 [debug] [MainThread]: Flushing usage events
[0m14:11:41.067461 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:11:42.320925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8b71490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8f52a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8b73f50>]}


============================== 14:11:42.324747 | 0b2159e1-df75-45a6-ab82-049f2090a4a2 ==============================
[0m14:11:42.324747 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:11:42.325224 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select vault.satellites', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:11:42.412194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8aef210>]}
[0m14:11:42.439805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb91e0350>]}
[0m14:11:42.440383 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:11:42.474347 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:11:42.535756 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:42.536289 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:42.555181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb867b650>]}
[0m14:11:42.607010 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:42.608554 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:42.619632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8b1e7d0>]}
[0m14:11:42.620084 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:11:42.620434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8afddd0>]}
[0m14:11:42.621401 [info ] [MainThread]: 
[0m14:11:42.621713 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:11:42.621985 [info ] [MainThread]: 
[0m14:11:42.622406 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:11:42.625635 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:11:42.631852 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:42.879006 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:11:42.880258 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:42.887586 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:11:42.891272 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:11:42.893607 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:42.895237 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaff32c90>]}
[0m14:11:42.897580 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_current
[0m14:11:42.898005 [info ] [Thread-1 (]: 1 of 3 START sql incremental model `edw`.`sat_product_current` ................. [RUN]
[0m14:11:42.898408 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.sat_product_current)
[0m14:11:42.898813 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_current
[0m14:11:42.907358 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_current"
[0m14:11:42.909183 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_current
[0m14:11:42.936513 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

    select name, type from system.columns where table = 'sat_product_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:11:42.938748 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:42.940758 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_current"
[0m14:11:42.941865 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

        insert into `edw`.`sat_product_current`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source")

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE (product_hash_key, product_hash_diff, load_date) NOT IN (
    SELECT product_hash_key, product_hash_diff, load_date
    FROM `edw`.`sat_product_current`
)

      ...
[0m14:11:42.958489 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m14:11:42.969109 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb53479d0>]}
[0m14:11:42.969719 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model `edw`.`sat_product_current` ............ [[32mOK[0m in 0.07s]
[0m14:11:42.970215 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_current
[0m14:11:42.970588 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_deal_current
[0m14:11:42.971082 [info ] [Thread-1 (]: 2 of 3 START sql incremental model `edw`.`sat_product_deal_current` ............ [RUN]
[0m14:11:42.971494 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_current, now model.clickhouse_edw.sat_product_deal_current)
[0m14:11:42.971815 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_deal_current
[0m14:11:42.974075 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_deal_current"
[0m14:11:42.975103 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_deal_current
[0m14:11:42.993520 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

            

    
        create table `edw`.`sat_product_deal_current`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


          )
        
        ...
[0m14:11:42.997852 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:43.003437 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

    select name, type from system.columns where table = 'sat_product_deal_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:11:43.005463 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:43.006613 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_deal_current"
[0m14:11:43.007554 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

        
  
    
    
    
        
         


        insert into `edw`.`sat_product_deal_current`
        ("product_deal_hash_key", "revenue_hash_diff", "revenue", "month", "quantity", "load_date", "record_source")

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


  
    ...
[0m14:11:43.010670 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:43.013812 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99d12790>]}
[0m14:11:43.014331 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model `edw`.`sat_product_deal_current` ....... [[32mOK[0m in 0.04s]
[0m14:11:43.014755 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_deal_current
[0m14:11:43.015083 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_history
[0m14:11:43.015481 [info ] [Thread-1 (]: 3 of 3 START sql table model `edw`.`sat_product_history` ....................... [RUN]
[0m14:11:43.015832 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_deal_current, now model.clickhouse_edw.sat_product_history)
[0m14:11:43.016152 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_history
[0m14:11:43.018920 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_history"
[0m14:11:43.019880 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_history
[0m14:11:43.063626 [debug] [Thread-1 (]: Creating new relation sat_product_history
[0m14:11:43.064695 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

            

    
        create table `edw`.`sat_product_history`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
          )
        
        ...
[0m14:11:43.070929 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:11:43.072839 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

    select name, type from system.columns where table = 'sat_product_history'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:11:43.074587 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:43.075968 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_history"
[0m14:11:43.077171 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

  
    
    
    
        
         


        insert into `edw`.`sat_product_history`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source", "load_end_date", "is_current")

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
  ...
[0m14:11:43.082695 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:11:43.084105 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

        OPTIMIZE TABLE `edw`.`sat_product_history` FINAL
      ...
[0m14:11:43.085838 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:11:43.086771 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b2159e1-df75-45a6-ab82-049f2090a4a2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb91db990>]}
[0m14:11:43.087294 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `edw`.`sat_product_history` .................. [[32mOK[0m in 0.07s]
[0m14:11:43.087709 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_history
[0m14:11:43.088672 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:11:43.089038 [debug] [MainThread]: Connection 'model.clickhouse_edw.sat_product_history' was left open.
[0m14:11:43.089496 [debug] [MainThread]: On model.clickhouse_edw.sat_product_history: Close
[0m14:11:43.089873 [info ] [MainThread]: 
[0m14:11:43.090216 [info ] [MainThread]: Finished running 2 incremental models, 1 table model in 0 hours 0 minutes and 0.47 seconds (0.47s).
[0m14:11:43.090806 [debug] [MainThread]: Command end result
[0m14:11:43.111571 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:43.112985 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:43.116560 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:11:43.116850 [info ] [MainThread]: 
[0m14:11:43.117182 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:11:43.117460 [info ] [MainThread]: 
[0m14:11:43.117745 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m14:11:43.118436 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8248002, "process_in_blocks": "0", "process_kernel_time": 0.133153, "process_mem_max_rss": "186992", "process_out_blocks": "2166", "process_user_time": 2.207549}
[0m14:11:43.118845 [debug] [MainThread]: Command `dbt run` succeeded at 14:11:43.118795 after 0.83 seconds
[0m14:11:43.119170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb8bd0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbcfa4350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffbcfd7f50>]}
[0m14:11:43.119482 [debug] [MainThread]: Flushing usage events
[0m14:11:44.191032 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:11:45.494578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0811690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0813ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0811150>]}


============================== 14:11:45.498135 | bd8866be-8547-4151-be9e-e249b0ff1e62 ==============================
[0m14:11:45.498135 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:11:45.498587 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt test', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:11:45.584467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bd8866be-8547-4151-be9e-e249b0ff1e62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb09ff290>]}
[0m14:11:45.614278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bd8866be-8547-4151-be9e-e249b0ff1e62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0c84410>]}
[0m14:11:45.615092 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:11:45.650662 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:11:45.711277 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:45.711742 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:45.730511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bd8866be-8547-4151-be9e-e249b0ff1e62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb04b79d0>]}
[0m14:11:45.774953 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:45.776397 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:45.792310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bd8866be-8547-4151-be9e-e249b0ff1e62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffaff598d0>]}
[0m14:11:45.792739 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:11:45.793041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bd8866be-8547-4151-be9e-e249b0ff1e62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb066a690>]}
[0m14:11:45.794003 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:11:45.795072 [debug] [MainThread]: Command end result
[0m14:11:45.813850 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:11:45.815108 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:11:45.817099 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:11:45.817702 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.34935838, "process_in_blocks": "0", "process_kernel_time": 0.095287, "process_mem_max_rss": "109628", "process_out_blocks": "2112", "process_user_time": 1.281872}
[0m14:11:45.818106 [debug] [MainThread]: Command `dbt test` succeeded at 14:11:45.818041 after 0.35 seconds
[0m14:11:45.818460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4af8350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb066b690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb4a3c750>]}
[0m14:11:45.818771 [debug] [MainThread]: Flushing usage events
[0m14:11:47.178904 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:32.135430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff865b3950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff865b0090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff837ce110>]}


============================== 14:24:32.140769 | fa6a16fe-1fc1-4952-8952-ab2858770aac ==============================
[0m14:24:32.140769 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:24:32.141290 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt debug', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:24:32.146203 [info ] [MainThread]: dbt version: 1.10.6
[0m14:24:32.146640 [info ] [MainThread]: python version: 3.11.5
[0m14:24:32.146982 [info ] [MainThread]: python path: /usr/local/bin/python
[0m14:24:32.147304 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.31
[0m14:24:32.177945 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt
[0m14:24:32.178413 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt/profiles.yml
[0m14:24:32.178733 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt/dbt_project.yml
[0m14:24:32.179138 [info ] [MainThread]: adapter type: clickhouse
[0m14:24:32.179446 [info ] [MainThread]: adapter version: 1.9.2
[0m14:24:32.227116 [info ] [MainThread]: Configuration:
[0m14:24:32.227555 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m14:24:32.227875 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m14:24:32.228191 [info ] [MainThread]: Required dependencies:
[0m14:24:32.228505 [debug] [MainThread]: Executing "git --help"
[0m14:24:32.229286 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m14:24:32.229596 [info ] [MainThread]: Connection:
[0m14:24:32.229891 [info ] [MainThread]:   driver: None
[0m14:24:32.230180 [info ] [MainThread]:   host: clickhouse-edw
[0m14:24:32.230465 [info ] [MainThread]:   port: 8123
[0m14:24:32.230743 [info ] [MainThread]:   user: default
[0m14:24:32.231015 [info ] [MainThread]:   schema: edw
[0m14:24:32.231323 [info ] [MainThread]:   retries: 1
[0m14:24:32.231609 [info ] [MainThread]:   cluster: None
[0m14:24:32.231888 [info ] [MainThread]:   database_engine: None
[0m14:24:32.232157 [info ] [MainThread]:   cluster_mode: False
[0m14:24:32.232437 [info ] [MainThread]:   secure: False
[0m14:24:32.232706 [info ] [MainThread]:   verify: False
[0m14:24:32.232970 [info ] [MainThread]:   client_cert: None
[0m14:24:32.233251 [info ] [MainThread]:   client_cert_key: None
[0m14:24:32.233524 [info ] [MainThread]:   connect_timeout: 10
[0m14:24:32.233798 [info ] [MainThread]:   send_receive_timeout: 300
[0m14:24:32.234067 [info ] [MainThread]:   sync_request_timeout: 5
[0m14:24:32.234337 [info ] [MainThread]:   compress_block_size: 1048576
[0m14:24:32.234614 [info ] [MainThread]:   compression: 
[0m14:24:32.234884 [info ] [MainThread]:   check_exchange: True
[0m14:24:32.235155 [info ] [MainThread]:   custom_settings: {'async_insert': 1, 'wait_for_async_insert': 1}
[0m14:24:32.235431 [info ] [MainThread]:   use_lw_deletes: False
[0m14:24:32.235708 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m14:24:32.236017 [info ] [MainThread]:   tcp_keepalive: False
[0m14:24:32.236366 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:24:32.267358 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m14:24:32.267785 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:24:32.551865 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m14:24:32.553610 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:32.562548 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m14:24:32.563065 [info ] [MainThread]: [31m1 check failed:[0m
[0m14:24:32.563494 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m14:24:32.564250 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.457785, "process_in_blocks": "0", "process_kernel_time": 0.175995, "process_mem_max_rss": "177784", "process_out_blocks": "1409", "process_user_time": 1.955952}
[0m14:24:32.564761 [debug] [MainThread]: Command `dbt debug` failed at 14:24:32.564694 after 0.46 seconds
[0m14:24:32.565112 [debug] [MainThread]: Connection 'debug' was left open.
[0m14:24:32.565414 [debug] [MainThread]: On debug: Close
[0m14:24:32.565844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff83b2b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff837d4150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff69f626d0>]}
[0m14:24:32.566340 [debug] [MainThread]: Flushing usage events
[0m14:24:33.845769 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:35.085122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89f4a410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89f4bc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89f4a250>]}


============================== 14:24:35.088971 | c219ee14-2be3-4875-a292-5ae105a424ce ==============================
[0m14:24:35.088971 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:24:35.089472 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select staging', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:24:35.178102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89d2ae10>]}
[0m14:24:35.208267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a3bc390>]}
[0m14:24:35.209006 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:24:35.244643 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:24:35.308753 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:24:35.309209 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:24:35.328450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89a13190>]}
[0m14:24:35.373901 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:35.375444 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:35.386744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89d79510>]}
[0m14:24:35.387197 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:24:35.387553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89bcbe50>]}
[0m14:24:35.388586 [info ] [MainThread]: 
[0m14:24:35.388923 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:35.389193 [info ] [MainThread]: 
[0m14:24:35.389627 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:24:35.392811 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:24:35.399079 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:35.717216 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:24:35.718804 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:35.728129 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:24:35.731999 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:24:35.735249 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:35.736937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8992c950>]}
[0m14:24:35.739445 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product
[0m14:24:35.740120 [info ] [Thread-1 (]: 1 of 2 START sql view model `edw`.`stg_product` ................................ [RUN]
[0m14:24:35.740662 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.stg_product)
[0m14:24:35.741072 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product
[0m14:24:35.746578 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product"
[0m14:24:35.748409 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product
[0m14:24:35.756566 [debug] [Thread-1 (]: Creating new relation stg_product
[0m14:24:35.764210 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product"
[0m14:24:35.765796 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product"} */


  create or replace view `edw`.`stg_product` 
  
    
  
  
    
    
  as (
    

WITH source_data AS (
    SELECT DISTINCT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        deal_name,
        load_date,
        record_source,
        product_hash_key,
        deal_hash_key,
        product_deal_hash_key,
        product_hash_diff
    FROM `edw`.`stg_products`
),

normalized_products AS (
    SELECT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        product_hash_key,
        product_hash_diff,
        max(load_date) AS load_date,
        max(record_source) AS record_source
    FROM source_data
    GROUP BY
        product_base_id, product_name, product_description,
        category, brand, product_rating, product_image,
        shop_name, shop_link, revenue, month, price, quantity,
        product_hash_key, product_hash_diff
)

SELECT * FROM normalized_products
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m14:24:35.769826 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:35.780794 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff67bc3690>]}
[0m14:24:35.781379 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `edw`.`stg_product` ........................... [[32mOK[0m in 0.04s]
[0m14:24:35.781907 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product
[0m14:24:35.782534 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product_deals
[0m14:24:35.783111 [info ] [Thread-1 (]: 2 of 2 START sql view model `edw`.`stg_product_deals` .......................... [RUN]
[0m14:24:35.783611 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.stg_product, now model.clickhouse_edw.stg_product_deals)
[0m14:24:35.784047 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product_deals
[0m14:24:35.786285 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product_deals"
[0m14:24:35.787365 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product_deals
[0m14:24:35.789051 [debug] [Thread-1 (]: Creating new relation stg_product_deals
[0m14:24:35.789912 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product_deals"
[0m14:24:35.790939 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product_deals: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product_deals"} */


  create or replace view `edw`.`stg_product_deals` 
  
    
  
  
    
    
  as (
    

SELECT DISTINCT
    product_base_id,
    deal_name,
    product_hash_key,
    deal_hash_key,
    product_deal_hash_key,
    max(load_date) AS load_date,
    max(record_source) AS record_source
FROM `edw`.`stg_products`
GROUP BY
    product_base_id, deal_name,
    product_hash_key, deal_hash_key, product_deal_hash_key
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m14:24:35.793430 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:35.794878 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c219ee14-2be3-4875-a292-5ae105a424ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89cd2e50>]}
[0m14:24:35.795395 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `edw`.`stg_product_deals` ..................... [[32mOK[0m in 0.01s]
[0m14:24:35.795856 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product_deals
[0m14:24:35.796832 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:35.797176 [debug] [MainThread]: Connection 'model.clickhouse_edw.stg_product_deals' was left open.
[0m14:24:35.797599 [debug] [MainThread]: On model.clickhouse_edw.stg_product_deals: Close
[0m14:24:35.798111 [info ] [MainThread]: 
[0m14:24:35.798437 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m14:24:35.798967 [debug] [MainThread]: Command end result
[0m14:24:35.863846 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:35.865371 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:35.869396 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:24:35.869806 [info ] [MainThread]: 
[0m14:24:35.870152 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:35.870470 [info ] [MainThread]: 
[0m14:24:35.870766 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m14:24:35.871535 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8147997, "process_in_blocks": "0", "process_kernel_time": 0.154488, "process_mem_max_rss": "184856", "process_out_blocks": "2142", "process_user_time": 2.165933}
[0m14:24:35.871961 [debug] [MainThread]: Command `dbt run` succeeded at 14:24:35.871909 after 0.82 seconds
[0m14:24:35.872298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a136a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e1685d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e224390>]}
[0m14:24:35.872643 [debug] [MainThread]: Flushing usage events
[0m14:24:36.917072 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:38.116574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84e15e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84e148d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84e167d0>]}


============================== 14:24:38.120192 | e993e0ec-b079-4b3e-8d06-032e794e8d97 ==============================
[0m14:24:38.120192 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:24:38.120635 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select vault.hubs', 'send_anonymous_usage_stats': 'True'}
[0m14:24:38.206883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84a54710>]}
[0m14:24:38.234790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84bc5750>]}
[0m14:24:38.235377 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:24:38.270109 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:24:38.331153 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:24:38.331604 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:24:38.350131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8491ebd0>]}
[0m14:24:38.394874 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:38.396263 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:38.407016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84640690>]}
[0m14:24:38.407545 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:24:38.407876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff872c0fd0>]}
[0m14:24:38.408853 [info ] [MainThread]: 
[0m14:24:38.409164 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:38.409452 [info ] [MainThread]: 
[0m14:24:38.409840 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:24:38.412915 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:24:38.418959 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:38.666972 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:24:38.668245 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:38.676563 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:24:38.680227 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:24:38.682704 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:38.684485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6744e1d0>]}
[0m14:24:38.687069 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_deal
[0m14:24:38.687605 [info ] [Thread-1 (]: 1 of 2 START sql incremental model `edw`.`hub_deal` ............................ [RUN]
[0m14:24:38.688033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.hub_deal)
[0m14:24:38.688383 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_deal
[0m14:24:38.696340 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_deal"
[0m14:24:38.697572 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_deal
[0m14:24:38.724460 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

    select name, type from system.columns where table = 'hub_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:24:38.726638 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:38.728575 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_deal"
[0m14:24:38.729755 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

        insert into `edw`.`hub_deal`
        ("deal_hash_key", "deal_business_key", "load_date", "record_source")

WITH deal_data AS (
    SELECT DISTINCT
        deal_name,
        deal_hash_key,
        load_date,
        record_source
    FROM `edw`.`stg_product_deals`
    WHERE deal_name IS NOT NULL
)

SELECT
    deal_hash_key,
    deal_name AS deal_business_key,
    load_date,
    record_source
FROM deal_data


WHERE deal_hash_key NOT IN (
    SELECT deal_hash_key
    FROM `edw`.`hub_deal`
)

      ...
[0m14:24:38.734833 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:38.745284 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff65db8790>]}
[0m14:24:38.745889 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model `edw`.`hub_deal` ....................... [[32mOK[0m in 0.06s]
[0m14:24:38.746345 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_deal
[0m14:24:38.746737 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_product
[0m14:24:38.747160 [info ] [Thread-1 (]: 2 of 2 START sql incremental model `edw`.`hub_product` ......................... [RUN]
[0m14:24:38.747529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.hub_deal, now model.clickhouse_edw.hub_product)
[0m14:24:38.747850 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_product
[0m14:24:38.749968 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_product"
[0m14:24:38.751080 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_product
[0m14:24:38.754299 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

    select name, type from system.columns where table = 'hub_product'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:24:38.756303 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:38.757305 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_product"
[0m14:24:38.758363 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

        insert into `edw`.`hub_product`
        ("product_hash_key", "product_business_key", "load_date", "record_source")

SELECT DISTINCT
    product_hash_key,
    product_base_id AS product_business_key,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE product_hash_key NOT IN (
    SELECT product_hash_key
    FROM `edw`.`hub_product`
)

      ...
[0m14:24:38.765645 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:24:38.767120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e993e0ec-b079-4b3e-8d06-032e794e8d97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84748bd0>]}
[0m14:24:38.767625 [info ] [Thread-1 (]: 2 of 2 OK created sql incremental model `edw`.`hub_product` .................... [[32mOK[0m in 0.02s]
[0m14:24:38.768044 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_product
[0m14:24:38.768893 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:38.769207 [debug] [MainThread]: Connection 'model.clickhouse_edw.hub_product' was left open.
[0m14:24:38.769487 [debug] [MainThread]: On model.clickhouse_edw.hub_product: Close
[0m14:24:38.769842 [info ] [MainThread]: 
[0m14:24:38.770139 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 0.36 seconds (0.36s).
[0m14:24:38.770661 [debug] [MainThread]: Command end result
[0m14:24:38.829749 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:38.831308 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:38.834978 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:24:38.835306 [info ] [MainThread]: 
[0m14:24:38.835675 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:38.835971 [info ] [MainThread]: 
[0m14:24:38.836323 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m14:24:38.837026 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.74705756, "process_in_blocks": "0", "process_kernel_time": 0.133753, "process_mem_max_rss": "186568", "process_out_blocks": "2133", "process_user_time": 2.136058}
[0m14:24:38.837427 [debug] [MainThread]: Command `dbt run` succeeded at 14:24:38.837367 after 0.75 seconds
[0m14:24:38.837754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff890f82d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84c78610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8903c810>]}
[0m14:24:38.838083 [debug] [MainThread]: Flushing usage events
[0m14:24:40.059831 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:41.306651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f505c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff81991f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f505c50>]}


============================== 14:24:41.310513 | a2b40096-9bbe-4d0c-bdb1-45aa6c0af546 ==============================
[0m14:24:41.310513 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:24:41.311047 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select vault.links', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:24:41.398913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a2b40096-9bbe-4d0c-bdb1-45aa6c0af546', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f506790>]}
[0m14:24:41.427080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a2b40096-9bbe-4d0c-bdb1-45aa6c0af546', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f2b5c10>]}
[0m14:24:41.427782 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:24:41.462114 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:24:41.524262 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:24:41.524762 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:24:41.543921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a2b40096-9bbe-4d0c-bdb1-45aa6c0af546', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f399310>]}
[0m14:24:41.592866 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:41.594339 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:41.605716 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a2b40096-9bbe-4d0c-bdb1-45aa6c0af546', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7eed6b50>]}
[0m14:24:41.606202 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:24:41.606584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2b40096-9bbe-4d0c-bdb1-45aa6c0af546', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f3a7650>]}
[0m14:24:41.607579 [info ] [MainThread]: 
[0m14:24:41.607971 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:41.608313 [info ] [MainThread]: 
[0m14:24:41.608754 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:24:41.609456 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:24:41.615515 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:41.856255 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:24:41.857685 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:41.868251 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:24:41.872028 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:24:41.874393 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:41.876073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a2b40096-9bbe-4d0c-bdb1-45aa6c0af546', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f1afe50>]}
[0m14:24:41.878526 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.link_product_deal
[0m14:24:41.879003 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `edw`.`link_product_deal` ................... [RUN]
[0m14:24:41.879408 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.link_product_deal)
[0m14:24:41.879773 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.link_product_deal
[0m14:24:41.887471 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.link_product_deal"
[0m14:24:41.888570 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.link_product_deal
[0m14:24:41.915575 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

    select name, type from system.columns where table = 'link_product_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:24:41.917628 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:41.919545 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.link_product_deal"
[0m14:24:41.920690 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

        insert into `edw`.`link_product_deal`
        ("product_deal_hash_key", "product_hash_key", "deal_hash_key", "load_date", "record_source")

SELECT DISTINCT
    product_deal_hash_key,
    product_hash_key,
    deal_hash_key,
    load_date,
    record_source
FROM `edw`.`stg_product_deals`
WHERE product_hash_key IS NOT NULL
  AND deal_hash_key IS NOT NULL


AND product_deal_hash_key NOT IN (
    SELECT product_deal_hash_key
    FROM `edw`.`link_product_deal`
)

      ...
[0m14:24:41.925385 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:41.936261 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a2b40096-9bbe-4d0c-bdb1-45aa6c0af546', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff604380d0>]}
[0m14:24:41.936870 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model `edw`.`link_product_deal` .............. [[32mOK[0m in 0.06s]
[0m14:24:41.937346 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.link_product_deal
[0m14:24:41.938315 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:41.938765 [debug] [MainThread]: Connection 'model.clickhouse_edw.link_product_deal' was left open.
[0m14:24:41.939150 [debug] [MainThread]: On model.clickhouse_edw.link_product_deal: Close
[0m14:24:41.939506 [info ] [MainThread]: 
[0m14:24:41.939827 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.33 seconds (0.33s).
[0m14:24:41.940322 [debug] [MainThread]: Command end result
[0m14:24:41.999307 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:42.000897 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:42.004412 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:24:42.004751 [info ] [MainThread]: 
[0m14:24:42.005122 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:42.005436 [info ] [MainThread]: 
[0m14:24:42.005771 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m14:24:42.006530 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.7278111, "process_in_blocks": "0", "process_kernel_time": 0.123933, "process_mem_max_rss": "186308", "process_out_blocks": "2125", "process_user_time": 2.164833}
[0m14:24:42.006955 [debug] [MainThread]: Command `dbt run` succeeded at 14:24:42.006888 after 0.73 seconds
[0m14:24:42.007304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff837d4250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f79f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff83755910>]}
[0m14:24:42.007632 [debug] [MainThread]: Flushing usage events
[0m14:24:43.209461 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:44.447970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff971cb5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff97414790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff971cb690>]}


============================== 14:24:44.451556 | 183b29ae-c146-4145-b64f-b4edc348aaf7 ==============================
[0m14:24:44.451556 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:24:44.452005 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select vault.satellites', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:24:44.541250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff970f5210>]}
[0m14:24:44.574672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9711d6d0>]}
[0m14:24:44.577259 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:24:44.614913 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:24:44.679478 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:24:44.680105 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:24:44.700549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff96dbcc50>]}
[0m14:24:44.746526 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:44.748111 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:44.759318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff997fca50>]}
[0m14:24:44.759779 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:24:44.760102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99013210>]}
[0m14:24:44.761073 [info ] [MainThread]: 
[0m14:24:44.761440 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:44.761724 [info ] [MainThread]: 
[0m14:24:44.762147 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m14:24:44.765499 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m14:24:44.771836 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:45.029246 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m14:24:45.030668 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.038478 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m14:24:45.042361 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m14:24:45.044841 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.046678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff99f3c590>]}
[0m14:24:45.049275 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_current
[0m14:24:45.049761 [info ] [Thread-1 (]: 1 of 3 START sql incremental model `edw`.`sat_product_current` ................. [RUN]
[0m14:24:45.050192 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.sat_product_current)
[0m14:24:45.050539 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_current
[0m14:24:45.058571 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_current"
[0m14:24:45.059965 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_current
[0m14:24:45.088686 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

    select name, type from system.columns where table = 'sat_product_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:24:45.091055 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.093370 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_current"
[0m14:24:45.094759 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

        insert into `edw`.`sat_product_current`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source")

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE (product_hash_key, product_hash_diff, load_date) NOT IN (
    SELECT product_hash_key, product_hash_diff, load_date
    FROM `edw`.`sat_product_current`
)

      ...
[0m14:24:45.112106 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m14:24:45.122961 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff783248d0>]}
[0m14:24:45.123609 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model `edw`.`sat_product_current` ............ [[32mOK[0m in 0.07s]
[0m14:24:45.124055 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_current
[0m14:24:45.124463 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_deal_current
[0m14:24:45.125025 [info ] [Thread-1 (]: 2 of 3 START sql incremental model `edw`.`sat_product_deal_current` ............ [RUN]
[0m14:24:45.125489 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_current, now model.clickhouse_edw.sat_product_deal_current)
[0m14:24:45.125823 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_deal_current
[0m14:24:45.128307 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_deal_current"
[0m14:24:45.129288 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_deal_current
[0m14:24:45.147707 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

            

    
        create table `edw`.`sat_product_deal_current`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


          )
        
        ...
[0m14:24:45.152140 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.157687 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

    select name, type from system.columns where table = 'sat_product_deal_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:24:45.159743 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.160980 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_deal_current"
[0m14:24:45.162033 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

        
  
    
    
    
        
         


        insert into `edw`.`sat_product_deal_current`
        ("product_deal_hash_key", "revenue_hash_diff", "revenue", "month", "quantity", "load_date", "record_source")

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


  
    ...
[0m14:24:45.164490 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.167770 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff78cb0f10>]}
[0m14:24:45.168337 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model `edw`.`sat_product_deal_current` ....... [[32mOK[0m in 0.04s]
[0m14:24:45.168780 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_deal_current
[0m14:24:45.169133 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_history
[0m14:24:45.169535 [info ] [Thread-1 (]: 3 of 3 START sql table model `edw`.`sat_product_history` ....................... [RUN]
[0m14:24:45.169905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_deal_current, now model.clickhouse_edw.sat_product_history)
[0m14:24:45.170226 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_history
[0m14:24:45.173131 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_history"
[0m14:24:45.174178 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_history
[0m14:24:45.220194 [debug] [Thread-1 (]: Creating new relation sat_product_history
[0m14:24:45.221400 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

            

    
        create table `edw`.`sat_product_history`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
          )
        
        ...
[0m14:24:45.230542 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:24:45.232549 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

    select name, type from system.columns where table = 'sat_product_history'
    
      and database = 'edw'
    
    order by position
  ...
[0m14:24:45.234591 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.236064 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_history"
[0m14:24:45.237308 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

  
    
    
    
        
         


        insert into `edw`.`sat_product_history`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source", "load_end_date", "is_current")

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
  ...
[0m14:24:45.243658 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m14:24:45.245123 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

        OPTIMIZE TABLE `edw`.`sat_product_history` FINAL
      ...
[0m14:24:45.247026 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m14:24:45.248093 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '183b29ae-c146-4145-b64f-b4edc348aaf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7824bfd0>]}
[0m14:24:45.248657 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `edw`.`sat_product_history` .................. [[32mOK[0m in 0.08s]
[0m14:24:45.249239 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_history
[0m14:24:45.250374 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:24:45.250783 [debug] [MainThread]: Connection 'model.clickhouse_edw.sat_product_history' was left open.
[0m14:24:45.251186 [debug] [MainThread]: On model.clickhouse_edw.sat_product_history: Close
[0m14:24:45.251633 [info ] [MainThread]: 
[0m14:24:45.251984 [info ] [MainThread]: Finished running 2 incremental models, 1 table model in 0 hours 0 minutes and 0.49 seconds (0.49s).
[0m14:24:45.252588 [debug] [MainThread]: Command end result
[0m14:24:45.274862 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:45.276444 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:45.280217 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:24:45.280546 [info ] [MainThread]: 
[0m14:24:45.280916 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:45.281208 [info ] [MainThread]: 
[0m14:24:45.281530 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m14:24:45.282240 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8604664, "process_in_blocks": "0", "process_kernel_time": 0.149417, "process_mem_max_rss": "186472", "process_out_blocks": "2166", "process_user_time": 2.119737}
[0m14:24:45.282656 [debug] [MainThread]: Command `dbt run` succeeded at 14:24:45.282601 after 0.86 seconds
[0m14:24:45.282981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9b5c0450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9b6c1510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9b5a5310>]}
[0m14:24:45.283351 [debug] [MainThread]: Flushing usage events
[0m14:24:46.349553 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:24:47.643876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82b66d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82b65e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82b64d10>]}


============================== 14:24:47.647709 | adae3e53-1793-40b7-98d2-362e2579a5c1 ==============================
[0m14:24:47.647709 [info ] [MainThread]: Running with dbt=1.10.6
[0m14:24:47.648249 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt test', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:24:47.735103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'adae3e53-1793-40b7-98d2-362e2579a5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82af1650>]}
[0m14:24:47.763339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'adae3e53-1793-40b7-98d2-362e2579a5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff831d4410>]}
[0m14:24:47.763991 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m14:24:47.798843 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m14:24:47.860484 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:24:47.860975 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:24:47.880354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'adae3e53-1793-40b7-98d2-362e2579a5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82684290>]}
[0m14:24:47.924855 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:47.926450 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:47.942208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'adae3e53-1793-40b7-98d2-362e2579a5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff824a17d0>]}
[0m14:24:47.942685 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m14:24:47.943013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'adae3e53-1793-40b7-98d2-362e2579a5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff82bc4610>]}
[0m14:24:47.944040 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:24:47.945193 [debug] [MainThread]: Command end result
[0m14:24:47.964611 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m14:24:47.965869 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m14:24:47.967903 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m14:24:47.968568 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.353815, "process_in_blocks": "0", "process_kernel_time": 0.095088, "process_mem_max_rss": "109680", "process_out_blocks": "2112", "process_user_time": 1.282198}
[0m14:24:47.968967 [debug] [MainThread]: Command `dbt test` succeeded at 14:24:47.968914 after 0.35 seconds
[0m14:24:47.969308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86f75810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86ff4410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86ff4590>]}
[0m14:24:47.969674 [debug] [MainThread]: Flushing usage events
[0m14:24:49.061275 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:34:36.976100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e97e3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9f7b9e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e97ebd0>]}


============================== 07:34:36.980558 | 59f73dd4-4267-4ab8-ae06-159e5328ed2a ==============================
[0m07:34:36.980558 [info ] [MainThread]: Running with dbt=1.10.6
[0m07:34:36.981053 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m07:34:36.987708 [info ] [MainThread]: dbt version: 1.10.6
[0m07:34:36.988045 [info ] [MainThread]: python version: 3.11.5
[0m07:34:36.988292 [info ] [MainThread]: python path: /usr/local/bin/python
[0m07:34:36.988531 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.31
[0m07:34:37.022886 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt
[0m07:34:37.023368 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt/profiles.yml
[0m07:34:37.023661 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt/dbt_project.yml
[0m07:34:37.024153 [info ] [MainThread]: adapter type: clickhouse
[0m07:34:37.024465 [info ] [MainThread]: adapter version: 1.9.2
[0m07:34:37.071570 [info ] [MainThread]: Configuration:
[0m07:34:37.072021 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m07:34:37.072425 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m07:34:37.072810 [info ] [MainThread]: Required dependencies:
[0m07:34:37.073137 [debug] [MainThread]: Executing "git --help"
[0m07:34:37.077147 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m07:34:37.077444 [info ] [MainThread]: Connection:
[0m07:34:37.077762 [info ] [MainThread]:   driver: None
[0m07:34:37.078033 [info ] [MainThread]:   host: clickhouse-edw
[0m07:34:37.078293 [info ] [MainThread]:   port: 8123
[0m07:34:37.078565 [info ] [MainThread]:   user: default
[0m07:34:37.078839 [info ] [MainThread]:   schema: edw
[0m07:34:37.079142 [info ] [MainThread]:   retries: 1
[0m07:34:37.079409 [info ] [MainThread]:   cluster: None
[0m07:34:37.079671 [info ] [MainThread]:   database_engine: None
[0m07:34:37.079934 [info ] [MainThread]:   cluster_mode: False
[0m07:34:37.080189 [info ] [MainThread]:   secure: False
[0m07:34:37.080450 [info ] [MainThread]:   verify: False
[0m07:34:37.080701 [info ] [MainThread]:   client_cert: None
[0m07:34:37.080983 [info ] [MainThread]:   client_cert_key: None
[0m07:34:37.081260 [info ] [MainThread]:   connect_timeout: 10
[0m07:34:37.081546 [info ] [MainThread]:   send_receive_timeout: 300
[0m07:34:37.081825 [info ] [MainThread]:   sync_request_timeout: 5
[0m07:34:37.082096 [info ] [MainThread]:   compress_block_size: 1048576
[0m07:34:37.082369 [info ] [MainThread]:   compression: 
[0m07:34:37.082650 [info ] [MainThread]:   check_exchange: True
[0m07:34:37.082923 [info ] [MainThread]:   custom_settings: {'async_insert': 1, 'wait_for_async_insert': 1}
[0m07:34:37.083193 [info ] [MainThread]:   use_lw_deletes: False
[0m07:34:37.083560 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m07:34:37.083828 [info ] [MainThread]:   tcp_keepalive: False
[0m07:34:37.084191 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m07:34:37.119562 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m07:34:37.120120 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:34:37.436201 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m07:34:37.437829 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:37.448023 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m07:34:37.448460 [info ] [MainThread]: [31m1 check failed:[0m
[0m07:34:37.448778 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m07:34:37.449471 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.50550324, "process_in_blocks": "54624", "process_kernel_time": 0.161915, "process_mem_max_rss": "175200", "process_out_blocks": "1409", "process_user_time": 2.067691}
[0m07:34:37.449882 [debug] [MainThread]: Command `dbt debug` failed at 07:34:37.449820 after 0.51 seconds
[0m07:34:37.450213 [debug] [MainThread]: Connection 'debug' was left open.
[0m07:34:37.450547 [debug] [MainThread]: On debug: Close
[0m07:34:37.450972 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9ed2b9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9e782790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff86da7350>]}
[0m07:34:37.451348 [debug] [MainThread]: Flushing usage events
[0m07:34:38.582298 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:34:39.914092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1651a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1650750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1653f10>]}


============================== 07:34:39.918306 | d6f0b752-141f-4ba2-ac00-c02a9ba725b9 ==============================
[0m07:34:39.918306 [info ] [MainThread]: Running with dbt=1.10.6
[0m07:34:39.919023 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select staging', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:34:40.048748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1291fd0>]}
[0m07:34:40.081566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb1401b50>]}
[0m07:34:40.082306 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m07:34:40.120692 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m07:34:40.202794 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:34:40.203356 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:34:40.223531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb0f64250>]}
[0m07:34:40.274859 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:40.276683 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:40.290316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3b5c8d0>]}
[0m07:34:40.290859 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m07:34:40.291198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb237ac50>]}
[0m07:34:40.292201 [info ] [MainThread]: 
[0m07:34:40.292530 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:34:40.292836 [info ] [MainThread]: 
[0m07:34:40.293249 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:34:40.296621 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m07:34:40.302931 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:34:40.561776 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m07:34:40.563233 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:40.571251 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m07:34:40.575264 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m07:34:40.580600 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:40.582284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff925e4e50>]}
[0m07:34:40.585077 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product
[0m07:34:40.585678 [info ] [Thread-1 (]: 1 of 2 START sql view model `edw`.`stg_product` ................................ [RUN]
[0m07:34:40.586114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.stg_product)
[0m07:34:40.586450 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product
[0m07:34:40.591421 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product"
[0m07:34:40.593088 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product
[0m07:34:40.600564 [debug] [Thread-1 (]: Creating new relation stg_product
[0m07:34:40.608382 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product"
[0m07:34:40.610007 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product"} */


  create or replace view `edw`.`stg_product` 
  
    
  
  
    
    
  as (
    

WITH source_data AS (
    SELECT DISTINCT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        deal_name,
        load_date,
        record_source,
        product_hash_key,
        deal_hash_key,
        product_deal_hash_key,
        product_hash_diff
    FROM `edw`.`stg_products`
),

normalized_products AS (
    SELECT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        product_hash_key,
        product_hash_diff,
        max(load_date) AS load_date,
        max(record_source) AS record_source
    FROM source_data
    GROUP BY
        product_base_id, product_name, product_description,
        category, brand, product_rating, product_image,
        shop_name, shop_link, revenue, month, price, quantity,
        product_hash_key, product_hash_diff
)

SELECT * FROM normalized_products
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m07:34:40.614110 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:40.625288 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9256ed10>]}
[0m07:34:40.625941 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `edw`.`stg_product` ........................... [[32mOK[0m in 0.04s]
[0m07:34:40.626395 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product
[0m07:34:40.626733 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product_deals
[0m07:34:40.627158 [info ] [Thread-1 (]: 2 of 2 START sql view model `edw`.`stg_product_deals` .......................... [RUN]
[0m07:34:40.627560 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.stg_product, now model.clickhouse_edw.stg_product_deals)
[0m07:34:40.627892 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product_deals
[0m07:34:40.629943 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product_deals"
[0m07:34:40.631104 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product_deals
[0m07:34:40.632609 [debug] [Thread-1 (]: Creating new relation stg_product_deals
[0m07:34:40.633363 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product_deals"
[0m07:34:40.634683 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product_deals: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product_deals"} */


  create or replace view `edw`.`stg_product_deals` 
  
    
  
  
    
    
  as (
    

SELECT DISTINCT
    product_base_id,
    deal_name,
    product_hash_key,
    deal_hash_key,
    product_deal_hash_key,
    max(load_date) AS load_date,
    max(record_source) AS record_source
FROM `edw`.`stg_products`
GROUP BY
    product_base_id, deal_name,
    product_hash_key, deal_hash_key, product_deal_hash_key
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m07:34:40.637342 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:40.638802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6f0b752-141f-4ba2-ac00-c02a9ba725b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb10a6190>]}
[0m07:34:40.639347 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `edw`.`stg_product_deals` ..................... [[32mOK[0m in 0.01s]
[0m07:34:40.639755 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product_deals
[0m07:34:40.640748 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:34:40.641135 [debug] [MainThread]: Connection 'model.clickhouse_edw.stg_product_deals' was left open.
[0m07:34:40.641576 [debug] [MainThread]: On model.clickhouse_edw.stg_product_deals: Close
[0m07:34:40.642129 [info ] [MainThread]: 
[0m07:34:40.642593 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.35 seconds (0.35s).
[0m07:34:40.643165 [debug] [MainThread]: Command end result
[0m07:34:40.705219 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:40.706716 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:40.710653 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:34:40.710941 [info ] [MainThread]: 
[0m07:34:40.711266 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:34:40.711551 [info ] [MainThread]: 
[0m07:34:40.711846 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m07:34:40.712546 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8365739, "process_in_blocks": "5024", "process_kernel_time": 0.161149, "process_mem_max_rss": "182760", "process_out_blocks": "2142", "process_user_time": 2.239983}
[0m07:34:40.712939 [debug] [MainThread]: Command `dbt run` succeeded at 07:34:40.712886 after 0.84 seconds
[0m07:34:40.713267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5910250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb58bc9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb5891950>]}
[0m07:34:40.713613 [debug] [MainThread]: Flushing usage events
[0m07:34:41.767830 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:34:43.094440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85166790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8554f290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8554f090>]}


============================== 07:34:43.098455 | ec2e658a-9916-450d-83ee-0103b7faead5 ==============================
[0m07:34:43.098455 [info ] [MainThread]: Running with dbt=1.10.6
[0m07:34:43.098914 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select vault.hubs', 'send_anonymous_usage_stats': 'True'}
[0m07:34:43.192733 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85111d90>]}
[0m07:34:43.223965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff857d4390>]}
[0m07:34:43.224961 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m07:34:43.261288 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m07:34:43.324516 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:34:43.324939 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:34:43.349483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84c84050>]}
[0m07:34:43.396828 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:43.398534 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:43.410030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff850e3e90>]}
[0m07:34:43.410570 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m07:34:43.410901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84fe4a10>]}
[0m07:34:43.411980 [info ] [MainThread]: 
[0m07:34:43.412303 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:34:43.412594 [info ] [MainThread]: 
[0m07:34:43.413085 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:34:43.416491 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m07:34:43.422853 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:34:43.691579 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m07:34:43.693096 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:43.701191 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m07:34:43.705470 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m07:34:43.708509 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:43.710366 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85110310>]}
[0m07:34:43.713209 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_deal
[0m07:34:43.713715 [info ] [Thread-1 (]: 1 of 2 START sql incremental model `edw`.`hub_deal` ............................ [RUN]
[0m07:34:43.714174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.hub_deal)
[0m07:34:43.714533 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_deal
[0m07:34:43.723077 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_deal"
[0m07:34:43.724734 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_deal
[0m07:34:43.752989 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

    select name, type from system.columns where table = 'hub_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m07:34:43.756688 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:43.759215 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_deal"
[0m07:34:43.760458 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

        insert into `edw`.`hub_deal`
        ("deal_hash_key", "deal_business_key", "load_date", "record_source")

WITH deal_data AS (
    SELECT DISTINCT
        deal_name,
        deal_hash_key,
        load_date,
        record_source
    FROM `edw`.`stg_product_deals`
    WHERE deal_name IS NOT NULL
)

SELECT
    deal_hash_key,
    deal_name AS deal_business_key,
    load_date,
    record_source
FROM deal_data


WHERE deal_hash_key NOT IN (
    SELECT deal_hash_key
    FROM `edw`.`hub_deal`
)

      ...
[0m07:34:43.769558 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:34:43.781290 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff662d0550>]}
[0m07:34:43.782065 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model `edw`.`hub_deal` ....................... [[32mOK[0m in 0.07s]
[0m07:34:43.782731 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_deal
[0m07:34:43.783162 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_product
[0m07:34:43.783716 [info ] [Thread-1 (]: 2 of 2 START sql incremental model `edw`.`hub_product` ......................... [RUN]
[0m07:34:43.784277 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.hub_deal, now model.clickhouse_edw.hub_product)
[0m07:34:43.784884 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_product
[0m07:34:43.787578 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_product"
[0m07:34:43.788726 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_product
[0m07:34:43.792285 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

    select name, type from system.columns where table = 'hub_product'
    
      and database = 'edw'
    
    order by position
  ...
[0m07:34:43.794985 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:43.796242 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_product"
[0m07:34:43.797546 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

        insert into `edw`.`hub_product`
        ("product_hash_key", "product_business_key", "load_date", "record_source")

SELECT DISTINCT
    product_hash_key,
    product_base_id AS product_business_key,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE product_hash_key NOT IN (
    SELECT product_hash_key
    FROM `edw`.`hub_product`
)

      ...
[0m07:34:43.807360 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:34:43.809058 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ec2e658a-9916-450d-83ee-0103b7faead5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84da0b50>]}
[0m07:34:43.809782 [info ] [Thread-1 (]: 2 of 2 OK created sql incremental model `edw`.`hub_product` .................... [[32mOK[0m in 0.02s]
[0m07:34:43.810290 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_product
[0m07:34:43.811703 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:34:43.812198 [debug] [MainThread]: Connection 'model.clickhouse_edw.hub_product' was left open.
[0m07:34:43.812685 [debug] [MainThread]: On model.clickhouse_edw.hub_product: Close
[0m07:34:43.813212 [info ] [MainThread]: 
[0m07:34:43.813568 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 0.40 seconds (0.40s).
[0m07:34:43.814122 [debug] [MainThread]: Command end result
[0m07:34:43.879279 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:43.880877 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:43.884737 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:34:43.885155 [info ] [MainThread]: 
[0m07:34:43.885537 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:34:43.885860 [info ] [MainThread]: 
[0m07:34:43.886140 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m07:34:43.886916 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.82216823, "process_in_blocks": "0", "process_kernel_time": 0.143974, "process_mem_max_rss": "186480", "process_out_blocks": "2133", "process_user_time": 2.308598}
[0m07:34:43.887418 [debug] [MainThread]: Command `dbt run` succeeded at 07:34:43.887340 after 0.82 seconds
[0m07:34:43.887858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8963c350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff85606490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6629bdd0>]}
[0m07:34:43.888274 [debug] [MainThread]: Flushing usage events
[0m07:34:44.884579 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:34:46.168997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0f740d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0f77150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0f74a90>]}


============================== 07:34:46.172833 | c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb ==============================
[0m07:34:46.172833 [info ] [MainThread]: Running with dbt=1.10.6
[0m07:34:46.173335 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select vault.links', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:34:46.259978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0f21750>]}
[0m07:34:46.299629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa15e4550>]}
[0m07:34:46.302812 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m07:34:46.351378 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m07:34:46.414303 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:34:46.414822 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:34:46.434207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0bc2810>]}
[0m07:34:46.480179 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:46.481658 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:46.493039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0adf3d0>]}
[0m07:34:46.493514 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m07:34:46.493867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa0d0f190>]}
[0m07:34:46.494882 [info ] [MainThread]: 
[0m07:34:46.495218 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:34:46.495634 [info ] [MainThread]: 
[0m07:34:46.496120 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:34:46.496916 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m07:34:46.503306 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:34:46.774163 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m07:34:46.775873 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:46.787089 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m07:34:46.791313 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m07:34:46.794280 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:46.796356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff93525e10>]}
[0m07:34:46.799212 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.link_product_deal
[0m07:34:46.799771 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `edw`.`link_product_deal` ................... [RUN]
[0m07:34:46.800243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.link_product_deal)
[0m07:34:46.800701 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.link_product_deal
[0m07:34:46.808827 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.link_product_deal"
[0m07:34:46.810312 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.link_product_deal
[0m07:34:46.839613 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

    select name, type from system.columns where table = 'link_product_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m07:34:46.842115 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:46.844672 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.link_product_deal"
[0m07:34:46.845996 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

        insert into `edw`.`link_product_deal`
        ("product_deal_hash_key", "product_hash_key", "deal_hash_key", "load_date", "record_source")

SELECT DISTINCT
    product_deal_hash_key,
    product_hash_key,
    deal_hash_key,
    load_date,
    record_source
FROM `edw`.`stg_product_deals`
WHERE product_hash_key IS NOT NULL
  AND deal_hash_key IS NOT NULL


AND product_deal_hash_key NOT IN (
    SELECT product_deal_hash_key
    FROM `edw`.`link_product_deal`
)

      ...
[0m07:34:46.851081 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:46.862502 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c6c87f8f-9f75-4bb9-b5de-7ebac0863ffb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa098a590>]}
[0m07:34:46.863247 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model `edw`.`link_product_deal` .............. [[32mOK[0m in 0.06s]
[0m07:34:46.863804 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.link_product_deal
[0m07:34:46.864940 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:34:46.865299 [debug] [MainThread]: Connection 'model.clickhouse_edw.link_product_deal' was left open.
[0m07:34:46.865653 [debug] [MainThread]: On model.clickhouse_edw.link_product_deal: Close
[0m07:34:46.866008 [info ] [MainThread]: 
[0m07:34:46.866335 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.37 seconds (0.37s).
[0m07:34:46.866816 [debug] [MainThread]: Command end result
[0m07:34:46.935824 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:46.937693 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:46.941754 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:34:46.942102 [info ] [MainThread]: 
[0m07:34:46.942467 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:34:46.942751 [info ] [MainThread]: 
[0m07:34:46.943048 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m07:34:46.943821 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.80453914, "process_in_blocks": "0", "process_kernel_time": 0.130309, "process_mem_max_rss": "186232", "process_out_blocks": "2125", "process_user_time": 2.196217}
[0m07:34:46.944231 [debug] [MainThread]: Command `dbt run` succeeded at 07:34:46.944162 after 0.81 seconds
[0m07:34:46.944595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa530c390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa528d950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1416290>]}
[0m07:34:46.944921 [debug] [MainThread]: Flushing usage events
[0m07:34:48.020640 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:34:49.257997 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2150cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2153c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2152390>]}


============================== 07:34:49.261824 | 283b5ded-3022-4f43-ae16-f9c1f3128b05 ==============================
[0m07:34:49.261824 [info ] [MainThread]: Running with dbt=1.10.6
[0m07:34:49.262404 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select vault.satellites', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:34:49.357333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1ff3290>]}
[0m07:34:49.388212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa25c4450>]}
[0m07:34:49.388999 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m07:34:49.424957 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m07:34:49.489646 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:34:49.490153 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:34:49.510816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1ba4910>]}
[0m07:34:49.560534 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:49.562234 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:49.577155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1eda350>]}
[0m07:34:49.577627 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m07:34:49.577946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa1e79d50>]}
[0m07:34:49.578908 [info ] [MainThread]: 
[0m07:34:49.579228 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:34:49.579525 [info ] [MainThread]: 
[0m07:34:49.579931 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m07:34:49.583289 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m07:34:49.589644 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:34:49.831343 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m07:34:49.832741 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:49.840518 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m07:34:49.844648 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m07:34:49.847046 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:49.848837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f7fb250>]}
[0m07:34:49.851396 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_current
[0m07:34:49.851866 [info ] [Thread-1 (]: 1 of 3 START sql incremental model `edw`.`sat_product_current` ................. [RUN]
[0m07:34:49.852287 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.sat_product_current)
[0m07:34:49.852646 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_current
[0m07:34:49.860574 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_current"
[0m07:34:49.862064 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_current
[0m07:34:49.889868 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

    select name, type from system.columns where table = 'sat_product_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m07:34:49.892153 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:49.894273 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_current"
[0m07:34:49.895607 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

        insert into `edw`.`sat_product_current`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source")

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE (product_hash_key, product_hash_diff, load_date) NOT IN (
    SELECT product_hash_key, product_hash_diff, load_date
    FROM `edw`.`sat_product_current`
)

      ...
[0m07:34:49.914699 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m07:34:49.925839 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f0d22d0>]}
[0m07:34:49.926454 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model `edw`.`sat_product_current` ............ [[32mOK[0m in 0.07s]
[0m07:34:49.926889 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_current
[0m07:34:49.927306 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_deal_current
[0m07:34:49.927791 [info ] [Thread-1 (]: 2 of 3 START sql incremental model `edw`.`sat_product_deal_current` ............ [RUN]
[0m07:34:49.928176 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_current, now model.clickhouse_edw.sat_product_deal_current)
[0m07:34:49.928503 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_deal_current
[0m07:34:49.930798 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_deal_current"
[0m07:34:49.931834 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_deal_current
[0m07:34:49.949417 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

            

    
        create table `edw`.`sat_product_deal_current`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


          )
        
        ...
[0m07:34:49.954033 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:49.959265 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

    select name, type from system.columns where table = 'sat_product_deal_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m07:34:49.961088 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:49.962173 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_deal_current"
[0m07:34:49.963079 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

        
  
    
    
    
        
         


        insert into `edw`.`sat_product_deal_current`
        ("product_deal_hash_key", "revenue_hash_diff", "revenue", "month", "quantity", "load_date", "record_source")

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


  
    ...
[0m07:34:49.965149 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:49.968168 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7e75ea50>]}
[0m07:34:49.968650 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model `edw`.`sat_product_deal_current` ....... [[32mOK[0m in 0.04s]
[0m07:34:49.969083 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_deal_current
[0m07:34:49.969420 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_history
[0m07:34:49.969794 [info ] [Thread-1 (]: 3 of 3 START sql table model `edw`.`sat_product_history` ....................... [RUN]
[0m07:34:49.970154 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_deal_current, now model.clickhouse_edw.sat_product_history)
[0m07:34:49.970499 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_history
[0m07:34:49.973176 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_history"
[0m07:34:49.974399 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_history
[0m07:34:50.018616 [debug] [Thread-1 (]: Creating new relation sat_product_history
[0m07:34:50.019879 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

            

    
        create table `edw`.`sat_product_history`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
          )
        
        ...
[0m07:34:50.026622 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:34:50.028716 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

    select name, type from system.columns where table = 'sat_product_history'
    
      and database = 'edw'
    
    order by position
  ...
[0m07:34:50.030603 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:50.032078 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_history"
[0m07:34:50.033309 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

  
    
    
    
        
         


        insert into `edw`.`sat_product_history`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source", "load_end_date", "is_current")

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
  ...
[0m07:34:50.040011 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m07:34:50.041433 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

        OPTIMIZE TABLE `edw`.`sat_product_history` FINAL
      ...
[0m07:34:50.043148 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m07:34:50.044203 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '283b5ded-3022-4f43-ae16-f9c1f3128b05', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff84333ed0>]}
[0m07:34:50.044744 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `edw`.`sat_product_history` .................. [[32mOK[0m in 0.07s]
[0m07:34:50.045209 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_history
[0m07:34:50.046182 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:34:50.046444 [debug] [MainThread]: Connection 'model.clickhouse_edw.sat_product_history' was left open.
[0m07:34:50.046693 [debug] [MainThread]: On model.clickhouse_edw.sat_product_history: Close
[0m07:34:50.047014 [info ] [MainThread]: 
[0m07:34:50.047257 [info ] [MainThread]: Finished running 2 incremental models, 1 table model in 0 hours 0 minutes and 0.47 seconds (0.47s).
[0m07:34:50.047757 [debug] [MainThread]: Command end result
[0m07:34:50.066378 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:50.067632 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:50.071087 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:34:50.071355 [info ] [MainThread]: 
[0m07:34:50.071644 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:34:50.071869 [info ] [MainThread]: 
[0m07:34:50.072100 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m07:34:50.072722 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8447789, "process_in_blocks": "0", "process_kernel_time": 0.132687, "process_mem_max_rss": "182360", "process_out_blocks": "2166", "process_user_time": 2.218777}
[0m07:34:50.073067 [debug] [MainThread]: Command `dbt run` succeeded at 07:34:50.073022 after 0.85 seconds
[0m07:34:50.073423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa233ea10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa233ed90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa64017d0>]}
[0m07:34:50.073694 [debug] [MainThread]: Flushing usage events
[0m07:34:51.112853 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:34:52.450251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9136dc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9180e110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9136c810>]}


============================== 07:34:52.454270 | db3e5a79-6e9a-4bb4-b8f5-299d526e10ba ==============================
[0m07:34:52.454270 [info ] [MainThread]: Running with dbt=1.10.6
[0m07:34:52.454759 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:34:52.543815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'db3e5a79-6e9a-4bb4-b8f5-299d526e10ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff911a9390>]}
[0m07:34:52.572418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'db3e5a79-6e9a-4bb4-b8f5-299d526e10ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff919dc350>]}
[0m07:34:52.573080 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m07:34:52.608176 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m07:34:52.664287 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:34:52.664707 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:34:52.683401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'db3e5a79-6e9a-4bb4-b8f5-299d526e10ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff9116ec10>]}
[0m07:34:52.725226 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:52.726539 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:52.743221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'db3e5a79-6e9a-4bb4-b8f5-299d526e10ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90ca9d90>]}
[0m07:34:52.743645 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m07:34:52.743968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'db3e5a79-6e9a-4bb4-b8f5-299d526e10ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90ced410>]}
[0m07:34:52.744875 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m07:34:52.745957 [debug] [MainThread]: Command end result
[0m07:34:52.762842 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:34:52.763980 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:34:52.765833 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:34:52.766419 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.34510016, "process_in_blocks": "1224", "process_kernel_time": 0.099251, "process_mem_max_rss": "109624", "process_out_blocks": "2112", "process_user_time": 1.276232}
[0m07:34:52.766769 [debug] [MainThread]: Command `dbt test` succeeded at 07:34:52.766721 after 0.35 seconds
[0m07:34:52.767067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95830410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95774590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff957ad590>]}
[0m07:34:52.767353 [debug] [MainThread]: Flushing usage events
[0m07:34:54.019974 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:06:41.318993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90fcbd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90faff90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90fcb290>]}


============================== 08:06:41.323661 | 79273b34-d542-47a8-bd56-6f28b7f635cd ==============================
[0m08:06:41.323661 [info ] [MainThread]: Running with dbt=1.10.6
[0m08:06:41.324256 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m08:06:41.331625 [info ] [MainThread]: dbt version: 1.10.6
[0m08:06:41.332039 [info ] [MainThread]: python version: 3.11.5
[0m08:06:41.332405 [info ] [MainThread]: python path: /usr/local/bin/python
[0m08:06:41.332728 [info ] [MainThread]: os info: Linux-6.10.14-linuxkit-aarch64-with-glibc2.31
[0m08:06:41.368564 [info ] [MainThread]: Using profiles dir at /opt/airflow/dbt
[0m08:06:41.369179 [info ] [MainThread]: Using profiles.yml file at /opt/airflow/dbt/profiles.yml
[0m08:06:41.369616 [info ] [MainThread]: Using dbt_project.yml file at /opt/airflow/dbt/dbt_project.yml
[0m08:06:41.370336 [info ] [MainThread]: adapter type: clickhouse
[0m08:06:41.370765 [info ] [MainThread]: adapter version: 1.9.2
[0m08:06:41.425507 [info ] [MainThread]: Configuration:
[0m08:06:41.426004 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m08:06:41.426387 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m08:06:41.426714 [info ] [MainThread]: Required dependencies:
[0m08:06:41.427073 [debug] [MainThread]: Executing "git --help"
[0m08:06:41.428201 [info ] [MainThread]:  - git [[31mERROR[0m]

[0m08:06:41.428609 [info ] [MainThread]: Connection:
[0m08:06:41.428989 [info ] [MainThread]:   driver: None
[0m08:06:41.429449 [info ] [MainThread]:   host: clickhouse-edw
[0m08:06:41.429898 [info ] [MainThread]:   port: 8123
[0m08:06:41.430250 [info ] [MainThread]:   user: default
[0m08:06:41.430626 [info ] [MainThread]:   schema: edw
[0m08:06:41.431104 [info ] [MainThread]:   retries: 1
[0m08:06:41.431495 [info ] [MainThread]:   cluster: None
[0m08:06:41.431852 [info ] [MainThread]:   database_engine: None
[0m08:06:41.432227 [info ] [MainThread]:   cluster_mode: False
[0m08:06:41.432593 [info ] [MainThread]:   secure: False
[0m08:06:41.432912 [info ] [MainThread]:   verify: False
[0m08:06:41.433254 [info ] [MainThread]:   client_cert: None
[0m08:06:41.433599 [info ] [MainThread]:   client_cert_key: None
[0m08:06:41.433900 [info ] [MainThread]:   connect_timeout: 10
[0m08:06:41.434201 [info ] [MainThread]:   send_receive_timeout: 300
[0m08:06:41.434497 [info ] [MainThread]:   sync_request_timeout: 5
[0m08:06:41.434785 [info ] [MainThread]:   compress_block_size: 1048576
[0m08:06:41.435094 [info ] [MainThread]:   compression: 
[0m08:06:41.435436 [info ] [MainThread]:   check_exchange: True
[0m08:06:41.435779 [info ] [MainThread]:   custom_settings: {'async_insert': 1, 'wait_for_async_insert': 1}
[0m08:06:41.436135 [info ] [MainThread]:   use_lw_deletes: False
[0m08:06:41.436484 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m08:06:41.436799 [info ] [MainThread]:   tcp_keepalive: False
[0m08:06:41.437257 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m08:06:41.477085 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m08:06:41.477492 [debug] [MainThread]: Opening a new connection, currently in state init
[0m08:06:41.802156 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m08:06:41.803618 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:41.814876 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m08:06:41.815294 [info ] [MainThread]: [31m1 check failed:[0m
[0m08:06:41.815637 [info ] [MainThread]: Error from git --help: User does not have permissions for this command: "git"

[0m08:06:41.816346 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.53039134, "process_in_blocks": "29032", "process_kernel_time": 0.210907, "process_mem_max_rss": "177088", "process_out_blocks": "1409", "process_user_time": 2.21453}
[0m08:06:41.816920 [debug] [MainThread]: Command `dbt debug` failed at 08:06:41.816800 after 0.53 seconds
[0m08:06:41.817415 [debug] [MainThread]: Connection 'debug' was left open.
[0m08:06:41.817848 [debug] [MainThread]: On debug: Close
[0m08:06:41.818233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90c968d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff72fa11d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff72fa1150>]}
[0m08:06:41.818590 [debug] [MainThread]: Flushing usage events
[0m08:06:43.119424 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:06:44.567961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a273090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a270f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a272990>]}


============================== 08:06:44.571778 | 2e73d46c-e114-479b-9310-ed47346e4088 ==============================
[0m08:06:44.571778 [info ] [MainThread]: Running with dbt=1.10.6
[0m08:06:44.572240 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select staging', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:06:44.695654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a23b610>]}
[0m08:06:44.729085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a8e0590>]}
[0m08:06:44.730031 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m08:06:44.774683 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m08:06:44.862380 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:06:44.862818 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:06:44.883449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89f36a90>]}
[0m08:06:44.939459 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:44.941429 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:44.955091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89f45190>]}
[0m08:06:44.955566 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m08:06:44.955893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8a00bc10>]}
[0m08:06:44.956852 [info ] [MainThread]: 
[0m08:06:44.957206 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:06:44.957511 [info ] [MainThread]: 
[0m08:06:44.957929 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m08:06:44.961255 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:06:44.967675 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:06:45.286730 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:06:45.288259 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:45.297245 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m08:06:45.302128 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m08:06:45.307616 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:45.309152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff89ef1b10>]}
[0m08:06:45.311919 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product
[0m08:06:45.312467 [info ] [Thread-1 (]: 1 of 2 START sql view model `edw`.`stg_product` ................................ [RUN]
[0m08:06:45.312857 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.stg_product)
[0m08:06:45.313171 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product
[0m08:06:45.318117 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product"
[0m08:06:45.319878 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product
[0m08:06:45.327501 [debug] [Thread-1 (]: Creating new relation stg_product
[0m08:06:45.335826 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product"
[0m08:06:45.337596 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product"} */


  create or replace view `edw`.`stg_product` 
  
    
  
  
    
    
  as (
    

WITH source_data AS (
    SELECT DISTINCT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        deal_name,
        load_date,
        record_source,
        product_hash_key,
        deal_hash_key,
        product_deal_hash_key,
        product_hash_diff
    FROM `edw`.`stg_products`
),

normalized_products AS (
    SELECT
        product_base_id,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        revenue,
        month,
        price,
        quantity,
        product_hash_key,
        product_hash_diff,
        max(load_date) AS load_date,
        max(record_source) AS record_source
    FROM source_data
    GROUP BY
        product_base_id, product_name, product_description,
        category, brand, product_rating, product_image,
        shop_name, shop_link, revenue, month, price, quantity,
        product_hash_key, product_hash_diff
)

SELECT * FROM normalized_products
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m08:06:45.341991 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:45.353653 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff67435f10>]}
[0m08:06:45.354306 [info ] [Thread-1 (]: 1 of 2 OK created sql view model `edw`.`stg_product` ........................... [[32mOK[0m in 0.04s]
[0m08:06:45.354791 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product
[0m08:06:45.355167 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.stg_product_deals
[0m08:06:45.355665 [info ] [Thread-1 (]: 2 of 2 START sql view model `edw`.`stg_product_deals` .......................... [RUN]
[0m08:06:45.356190 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.stg_product, now model.clickhouse_edw.stg_product_deals)
[0m08:06:45.356547 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.stg_product_deals
[0m08:06:45.359072 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.stg_product_deals"
[0m08:06:45.360251 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.stg_product_deals
[0m08:06:45.362318 [debug] [Thread-1 (]: Creating new relation stg_product_deals
[0m08:06:45.363229 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.stg_product_deals"
[0m08:06:45.364166 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.stg_product_deals: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.stg_product_deals"} */


  create or replace view `edw`.`stg_product_deals` 
  
    
  
  
    
    
  as (
    

SELECT DISTINCT
    product_base_id,
    deal_name,
    product_hash_key,
    deal_hash_key,
    product_deal_hash_key,
    max(load_date) AS load_date,
    max(record_source) AS record_source
FROM `edw`.`stg_products`
GROUP BY
    product_base_id, deal_name,
    product_hash_key, deal_hash_key, product_deal_hash_key
    
  )
      
      
                    -- end_of_sql
                    
                    ...
[0m08:06:45.366536 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:45.367899 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e73d46c-e114-479b-9310-ed47346e4088', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff6739ce10>]}
[0m08:06:45.368378 [info ] [Thread-1 (]: 2 of 2 OK created sql view model `edw`.`stg_product_deals` ..................... [[32mOK[0m in 0.01s]
[0m08:06:45.368787 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.stg_product_deals
[0m08:06:45.369763 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:06:45.370075 [debug] [MainThread]: Connection 'model.clickhouse_edw.stg_product_deals' was left open.
[0m08:06:45.370393 [debug] [MainThread]: On model.clickhouse_edw.stg_product_deals: Close
[0m08:06:45.370748 [info ] [MainThread]: 
[0m08:06:45.371156 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.41 seconds (0.41s).
[0m08:06:45.371751 [debug] [MainThread]: Command end result
[0m08:06:45.440242 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:45.442122 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:45.447423 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m08:06:45.447888 [info ] [MainThread]: 
[0m08:06:45.448369 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:06:45.448768 [info ] [MainThread]: 
[0m08:06:45.449174 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m08:06:45.450074 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.91775286, "process_in_blocks": "2800", "process_kernel_time": 0.165007, "process_mem_max_rss": "185188", "process_out_blocks": "2142", "process_user_time": 2.440109}
[0m08:06:45.450564 [debug] [MainThread]: Command `dbt run` succeeded at 08:06:45.450509 after 0.92 seconds
[0m08:06:45.450904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e7a4290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e6e8990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8e725950>]}
[0m08:06:45.451250 [debug] [MainThread]: Flushing usage events
[0m08:06:46.721518 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:06:48.213161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2772450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2771f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2773ad0>]}


============================== 08:06:48.217932 | 4350f5eb-40f6-4d90-8111-8344d20b69b2 ==============================
[0m08:06:48.217932 [info ] [MainThread]: Running with dbt=1.10.6
[0m08:06:48.218433 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --select vault.hubs', 'send_anonymous_usage_stats': 'True'}
[0m08:06:48.322777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa29e7650>]}
[0m08:06:48.361274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa26c95d0>]}
[0m08:06:48.362205 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m08:06:48.401085 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m08:06:48.471153 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:06:48.471707 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:06:48.493777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa2366190>]}
[0m08:06:48.549860 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:48.551507 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:48.563679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa26a2190>]}
[0m08:06:48.564143 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m08:06:48.564460 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa258cad0>]}
[0m08:06:48.565413 [info ] [MainThread]: 
[0m08:06:48.565755 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:06:48.566038 [info ] [MainThread]: 
[0m08:06:48.566497 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m08:06:48.569863 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:06:48.576356 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:06:48.869669 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:06:48.871152 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:48.879082 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m08:06:48.882982 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m08:06:48.885471 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:48.887133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa21bb590>]}
[0m08:06:48.890309 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_deal
[0m08:06:48.890817 [info ] [Thread-1 (]: 1 of 2 START sql incremental model `edw`.`hub_deal` ............................ [RUN]
[0m08:06:48.891298 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.hub_deal)
[0m08:06:48.891752 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_deal
[0m08:06:48.900624 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_deal"
[0m08:06:48.902349 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_deal
[0m08:06:48.934621 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

    select name, type from system.columns where table = 'hub_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m08:06:48.938081 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:48.940846 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_deal"
[0m08:06:48.942343 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_deal"} */

        insert into `edw`.`hub_deal`
        ("deal_hash_key", "deal_business_key", "load_date", "record_source")

WITH deal_data AS (
    SELECT DISTINCT
        deal_name,
        deal_hash_key,
        load_date,
        record_source
    FROM `edw`.`stg_product_deals`
    WHERE deal_name IS NOT NULL
)

SELECT
    deal_hash_key,
    deal_name AS deal_business_key,
    load_date,
    record_source
FROM deal_data


WHERE deal_hash_key NOT IN (
    SELECT deal_hash_key
    FROM `edw`.`hub_deal`
)

      ...
[0m08:06:48.951507 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:06:48.962784 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7f82a110>]}
[0m08:06:48.963564 [info ] [Thread-1 (]: 1 of 2 OK created sql incremental model `edw`.`hub_deal` ....................... [[32mOK[0m in 0.07s]
[0m08:06:48.964231 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_deal
[0m08:06:48.964723 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.hub_product
[0m08:06:48.965260 [info ] [Thread-1 (]: 2 of 2 START sql incremental model `edw`.`hub_product` ......................... [RUN]
[0m08:06:48.965780 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.hub_deal, now model.clickhouse_edw.hub_product)
[0m08:06:48.966244 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.hub_product
[0m08:06:48.969102 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.hub_product"
[0m08:06:48.970491 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.hub_product
[0m08:06:48.973791 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

    select name, type from system.columns where table = 'hub_product'
    
      and database = 'edw'
    
    order by position
  ...
[0m08:06:48.975927 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:48.977028 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.hub_product"
[0m08:06:48.978179 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.hub_product: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.hub_product"} */

        insert into `edw`.`hub_product`
        ("product_hash_key", "product_business_key", "load_date", "record_source")

SELECT DISTINCT
    product_hash_key,
    product_base_id AS product_business_key,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE product_hash_key NOT IN (
    SELECT product_hash_key
    FROM `edw`.`hub_product`
)

      ...
[0m08:06:48.986349 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:06:48.987863 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4350f5eb-40f6-4d90-8111-8344d20b69b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa22496d0>]}
[0m08:06:48.988373 [info ] [Thread-1 (]: 2 of 2 OK created sql incremental model `edw`.`hub_product` .................... [[32mOK[0m in 0.02s]
[0m08:06:48.988806 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.hub_product
[0m08:06:48.989760 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:06:48.990060 [debug] [MainThread]: Connection 'model.clickhouse_edw.hub_product' was left open.
[0m08:06:48.990421 [debug] [MainThread]: On model.clickhouse_edw.hub_product: Close
[0m08:06:48.990811 [info ] [MainThread]: 
[0m08:06:48.991146 [info ] [MainThread]: Finished running 2 incremental models in 0 hours 0 minutes and 0.42 seconds (0.42s).
[0m08:06:48.991682 [debug] [MainThread]: Command end result
[0m08:06:49.058269 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:49.060221 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:49.064712 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m08:06:49.065029 [info ] [MainThread]: 
[0m08:06:49.065385 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:06:49.065663 [info ] [MainThread]: 
[0m08:06:49.065950 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m08:06:49.066699 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.892296, "process_in_blocks": "0", "process_kernel_time": 0.165859, "process_mem_max_rss": "186512", "process_out_blocks": "2133", "process_user_time": 2.489896}
[0m08:06:49.067095 [debug] [MainThread]: Command `dbt run` succeeded at 08:06:49.067042 after 0.89 seconds
[0m08:06:49.067442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6af8390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6a3c810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffa6a798d0>]}
[0m08:06:49.067799 [debug] [MainThread]: Flushing usage events
[0m08:06:50.159089 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:06:51.574767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90c69dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90f822d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90c6a0d0>]}


============================== 08:06:51.579474 | 939bedca-f151-40c1-9aba-d9291f11ae65 ==============================
[0m08:06:51.579474 [info ] [MainThread]: Running with dbt=1.10.6
[0m08:06:51.580134 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run --select vault.links', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:06:51.681085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '939bedca-f151-40c1-9aba-d9291f11ae65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90c02850>]}
[0m08:06:51.716530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '939bedca-f151-40c1-9aba-d9291f11ae65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff912844d0>]}
[0m08:06:51.717363 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m08:06:51.756614 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m08:06:51.822199 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:06:51.822760 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:06:51.843727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '939bedca-f151-40c1-9aba-d9291f11ae65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff908dba10>]}
[0m08:06:51.897390 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:51.899297 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:51.913930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '939bedca-f151-40c1-9aba-d9291f11ae65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90a56a10>]}
[0m08:06:51.914464 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m08:06:51.914816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '939bedca-f151-40c1-9aba-d9291f11ae65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff909e4910>]}
[0m08:06:51.915848 [info ] [MainThread]: 
[0m08:06:51.916221 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:06:51.916515 [info ] [MainThread]: 
[0m08:06:51.916977 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m08:06:51.917716 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:06:51.924406 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:06:52.217846 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:06:52.219678 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:52.231064 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m08:06:52.236182 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m08:06:52.239310 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:52.241332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '939bedca-f151-40c1-9aba-d9291f11ae65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90e09bd0>]}
[0m08:06:52.244183 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.link_product_deal
[0m08:06:52.244850 [info ] [Thread-1 (]: 1 of 1 START sql incremental model `edw`.`link_product_deal` ................... [RUN]
[0m08:06:52.245558 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.link_product_deal)
[0m08:06:52.246040 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.link_product_deal
[0m08:06:52.254648 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.link_product_deal"
[0m08:06:52.256382 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.link_product_deal
[0m08:06:52.285552 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

    select name, type from system.columns where table = 'link_product_deal'
    
      and database = 'edw'
    
    order by position
  ...
[0m08:06:52.288153 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:52.290561 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.link_product_deal"
[0m08:06:52.292077 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.link_product_deal: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.link_product_deal"} */

        insert into `edw`.`link_product_deal`
        ("product_deal_hash_key", "product_hash_key", "deal_hash_key", "load_date", "record_source")

SELECT DISTINCT
    product_deal_hash_key,
    product_hash_key,
    deal_hash_key,
    load_date,
    record_source
FROM `edw`.`stg_product_deals`
WHERE product_hash_key IS NOT NULL
  AND deal_hash_key IS NOT NULL


AND product_deal_hash_key NOT IN (
    SELECT product_deal_hash_key
    FROM `edw`.`link_product_deal`
)

      ...
[0m08:06:52.297645 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:06:52.309596 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '939bedca-f151-40c1-9aba-d9291f11ae65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff71d95890>]}
[0m08:06:52.310402 [info ] [Thread-1 (]: 1 of 1 OK created sql incremental model `edw`.`link_product_deal` .............. [[32mOK[0m in 0.06s]
[0m08:06:52.310997 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.link_product_deal
[0m08:06:52.312368 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:06:52.312791 [debug] [MainThread]: Connection 'model.clickhouse_edw.link_product_deal' was left open.
[0m08:06:52.313151 [debug] [MainThread]: On model.clickhouse_edw.link_product_deal: Close
[0m08:06:52.313571 [info ] [MainThread]: 
[0m08:06:52.313996 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 0.40 seconds (0.40s).
[0m08:06:52.314603 [debug] [MainThread]: Command end result
[0m08:06:52.377668 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:52.379668 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:52.383759 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m08:06:52.384126 [info ] [MainThread]: 
[0m08:06:52.384631 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:06:52.385058 [info ] [MainThread]: 
[0m08:06:52.385485 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m08:06:52.386641 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.8455832, "process_in_blocks": "104", "process_kernel_time": 0.183845, "process_mem_max_rss": "186356", "process_out_blocks": "2125", "process_user_time": 2.366007}
[0m08:06:52.387200 [debug] [MainThread]: Command `dbt run` succeeded at 08:06:52.387065 after 0.85 seconds
[0m08:06:52.387615 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff95200190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff90ef0f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff950798d0>]}
[0m08:06:52.387959 [debug] [MainThread]: Flushing usage events
[0m08:06:53.476592 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:06:54.761561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f367790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f365e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f366490>]}


============================== 08:06:54.765342 | bf5359dc-03bb-4514-9d6a-e08e588b92c5 ==============================
[0m08:06:54.765342 [info ] [MainThread]: Running with dbt=1.10.6
[0m08:06:54.765818 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --select vault.satellites', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:06:54.869744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f609690>]}
[0m08:06:54.906000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f9d4350>]}
[0m08:06:54.906760 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m08:06:54.944860 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m08:06:55.016714 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:06:55.017330 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:06:55.039664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8efb0f90>]}
[0m08:06:55.093181 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:55.095145 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:55.111504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f2e8f10>]}
[0m08:06:55.112876 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m08:06:55.113631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8ed69d10>]}
[0m08:06:55.114940 [info ] [MainThread]: 
[0m08:06:55.115455 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:06:55.115847 [info ] [MainThread]: 
[0m08:06:55.116299 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m08:06:55.120309 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m08:06:55.126966 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:06:55.419304 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m08:06:55.420828 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.429216 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__edw)
[0m08:06:55.433025 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__edw: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "connection_name": "list__edw"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'edw'
      

  ...
[0m08:06:55.435472 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.437218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff719aa050>]}
[0m08:06:55.439913 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_current
[0m08:06:55.440398 [info ] [Thread-1 (]: 1 of 3 START sql incremental model `edw`.`sat_product_current` ................. [RUN]
[0m08:06:55.440830 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__edw, now model.clickhouse_edw.sat_product_current)
[0m08:06:55.441185 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_current
[0m08:06:55.449680 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_current"
[0m08:06:55.451998 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_current
[0m08:06:55.481361 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

    select name, type from system.columns where table = 'sat_product_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m08:06:55.483734 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.485830 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_current"
[0m08:06:55.486953 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_current"} */

        insert into `edw`.`sat_product_current`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source")

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source
FROM `edw`.`stg_product`


WHERE (product_hash_key, product_hash_diff, load_date) NOT IN (
    SELECT product_hash_key, product_hash_diff, load_date
    FROM `edw`.`sat_product_current`
)

      ...
[0m08:06:55.510529 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m08:06:55.521802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff7036c3d0>]}
[0m08:06:55.522385 [info ] [Thread-1 (]: 1 of 3 OK created sql incremental model `edw`.`sat_product_current` ............ [[32mOK[0m in 0.08s]
[0m08:06:55.522863 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_current
[0m08:06:55.523244 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_deal_current
[0m08:06:55.523770 [info ] [Thread-1 (]: 2 of 3 START sql incremental model `edw`.`sat_product_deal_current` ............ [RUN]
[0m08:06:55.524135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_current, now model.clickhouse_edw.sat_product_deal_current)
[0m08:06:55.524412 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_deal_current
[0m08:06:55.526612 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_deal_current"
[0m08:06:55.527429 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_deal_current
[0m08:06:55.545634 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

            

    
        create table `edw`.`sat_product_deal_current`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


          )
        
        ...
[0m08:06:55.550500 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.556189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

    select name, type from system.columns where table = 'sat_product_deal_current'
    
      and database = 'edw'
    
    order by position
  ...
[0m08:06:55.558200 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.559446 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_deal_current"
[0m08:06:55.560272 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_deal_current: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_deal_current"} */

        
  
    
    
    
        
         


        insert into `edw`.`sat_product_deal_current`
        ("product_deal_hash_key", "revenue_hash_diff", "revenue", "month", "quantity", "load_date", "record_source")

SELECT
    product_deal_hash_key,
    cityHash64(concat(
        toString(revenue), '||',
        month, '||',
        toString(quantity)
    )) AS revenue_hash_diff,
    revenue,
    month,
    quantity,
    load_date,
    record_source
FROM `edw`.`stg_products`


  
    ...
[0m08:06:55.562453 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.565767 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff703421d0>]}
[0m08:06:55.566257 [info ] [Thread-1 (]: 2 of 3 OK created sql incremental model `edw`.`sat_product_deal_current` ....... [[32mOK[0m in 0.04s]
[0m08:06:55.566648 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_deal_current
[0m08:06:55.566992 [debug] [Thread-1 (]: Began running node model.clickhouse_edw.sat_product_history
[0m08:06:55.567401 [info ] [Thread-1 (]: 3 of 3 START sql table model `edw`.`sat_product_history` ....................... [RUN]
[0m08:06:55.567733 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.clickhouse_edw.sat_product_deal_current, now model.clickhouse_edw.sat_product_history)
[0m08:06:55.567997 [debug] [Thread-1 (]: Began compiling node model.clickhouse_edw.sat_product_history
[0m08:06:55.571072 [debug] [Thread-1 (]: Writing injected SQL for node "model.clickhouse_edw.sat_product_history"
[0m08:06:55.572324 [debug] [Thread-1 (]: Began executing node model.clickhouse_edw.sat_product_history
[0m08:06:55.619172 [debug] [Thread-1 (]: Creating new relation sat_product_history
[0m08:06:55.620202 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

            

    
        create table `edw`.`sat_product_history`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
          )
        
        ...
[0m08:06:55.626898 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:06:55.628815 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

    select name, type from system.columns where table = 'sat_product_history'
    
      and database = 'edw'
    
    order by position
  ...
[0m08:06:55.630613 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.631966 [debug] [Thread-1 (]: Writing runtime sql for node "model.clickhouse_edw.sat_product_history"
[0m08:06:55.633059 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

  
    
    
    
        
         


        insert into `edw`.`sat_product_history`
        ("product_hash_key", "product_hash_diff", "product_name", "product_description", "category", "brand", "product_rating", "product_image", "shop_name", "shop_link", "price", "load_date", "record_source", "load_end_date", "is_current")

WITH ranked_data AS (
    SELECT
        product_hash_key,
        product_hash_diff,
        product_name,
        product_description,
        category,
        brand,
        product_rating,
        product_image,
        shop_name,
        shop_link,
        price,
        load_date,
        record_source,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date
        ) as rn,
        ROW_NUMBER() OVER (
            PARTITION BY product_hash_key
            ORDER BY load_date DESC
        ) as rn_desc
    FROM `edw`.`sat_product_current`
),

with_next_date AS (
    SELECT
        r1.product_hash_key,
        r1.product_hash_diff,
        r1.product_name,
        r1.product_description,
        r1.category,
        r1.brand,
        r1.product_rating,
        r1.product_image,
        r1.shop_name,
        r1.shop_link,
        r1.price,
        r1.load_date,
        r1.record_source,
        COALESCE(r2.load_date, toDateTime('9999-12-31 23:59:59')) AS load_end_date,
        CASE WHEN r1.rn_desc = 1 THEN 1 ELSE 0 END AS is_current
    FROM ranked_data r1
    LEFT JOIN ranked_data r2
        ON r1.product_hash_key = r2.product_hash_key
        AND r2.rn = r1.rn + 1
)

SELECT
    product_hash_key,
    product_hash_diff,
    product_name,
    product_description,
    category,
    brand,
    product_rating,
    product_image,
    shop_name,
    shop_link,
    price,
    load_date,
    record_source,
    load_end_date,
    is_current
FROM with_next_date
  ...
[0m08:06:55.639638 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m08:06:55.641012 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.clickhouse_edw.sat_product_history: /* {"app": "dbt", "dbt_version": "1.10.6", "profile_name": "clickhouse_edw", "target_name": "dev", "node_id": "model.clickhouse_edw.sat_product_history"} */

        OPTIMIZE TABLE `edw`.`sat_product_history` FINAL
      ...
[0m08:06:55.642894 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m08:06:55.643843 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf5359dc-03bb-4514-9d6a-e08e588b92c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff703c0710>]}
[0m08:06:55.644383 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `edw`.`sat_product_history` .................. [[32mOK[0m in 0.08s]
[0m08:06:55.644801 [debug] [Thread-1 (]: Finished running node model.clickhouse_edw.sat_product_history
[0m08:06:55.645923 [debug] [MainThread]: Connection 'master' was properly closed.
[0m08:06:55.646272 [debug] [MainThread]: Connection 'model.clickhouse_edw.sat_product_history' was left open.
[0m08:06:55.646568 [debug] [MainThread]: On model.clickhouse_edw.sat_product_history: Close
[0m08:06:55.646925 [info ] [MainThread]: 
[0m08:06:55.647224 [info ] [MainThread]: Finished running 2 incremental models, 1 table model in 0 hours 0 minutes and 0.53 seconds (0.53s).
[0m08:06:55.647828 [debug] [MainThread]: Command end result
[0m08:06:55.669133 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:55.670591 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:55.674390 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m08:06:55.674713 [info ] [MainThread]: 
[0m08:06:55.675067 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:06:55.675370 [info ] [MainThread]: 
[0m08:06:55.675659 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=3
[0m08:06:55.676333 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.9435265, "process_in_blocks": "0", "process_kernel_time": 0.145112, "process_mem_max_rss": "186592", "process_out_blocks": "2166", "process_user_time": 2.332804}
[0m08:06:55.676727 [debug] [MainThread]: Command `dbt run` succeeded at 08:06:55.676674 after 0.94 seconds
[0m08:06:55.677048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff8f3b9050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff937cc6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffff937a17d0>]}
[0m08:06:55.677373 [debug] [MainThread]: Flushing usage events
[0m08:06:56.752398 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:06:58.174310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3e71310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3e72010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3e70c90>]}


============================== 08:06:58.178748 | 8972a980-ab21-4131-82ff-0096881e854d ==============================
[0m08:06:58.178748 [info ] [MainThread]: Running with dbt=1.10.6
[0m08:06:58.179386 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt test', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m08:06:58.280039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8972a980-ab21-4131-82ff-0096881e854d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3def8d0>]}
[0m08:06:58.310117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8972a980-ab21-4131-82ff-0096881e854d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb44e0350>]}
[0m08:06:58.311073 [info ] [MainThread]: Registered adapter: clickhouse=1.9.2
[0m08:06:58.348306 [debug] [MainThread]: checksum: f6e4baf4de20596ffb9d14e6ef805989eb0e1950dedc3cc83d03f20aa023904c, vars: {}, profile: , target: , version: 1.10.6
[0m08:06:58.417096 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:06:58.417744 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:06:58.437650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8972a980-ab21-4131-82ff-0096881e854d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3ec6f50>]}
[0m08:06:58.490240 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:58.491894 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:58.510945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8972a980-ab21-4131-82ff-0096881e854d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb37adb10>]}
[0m08:06:58.511487 [info ] [MainThread]: Found 9 models, 1 source, 477 macros
[0m08:06:58.511863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8972a980-ab21-4131-82ff-0096881e854d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3b37550>]}
[0m08:06:58.512980 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m08:06:58.514238 [debug] [MainThread]: Command end result
[0m08:06:58.536181 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m08:06:58.537959 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m08:06:58.540367 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m08:06:58.541197 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 0.39779395, "process_in_blocks": "1224", "process_kernel_time": 0.124142, "process_mem_max_rss": "109808", "process_out_blocks": "2112", "process_user_time": 1.382583}
[0m08:06:58.541698 [debug] [MainThread]: Command `dbt test` succeeded at 08:06:58.541601 after 0.40 seconds
[0m08:06:58.542179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb83b8410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3ec7090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0xffffb3aad7d0>]}
[0m08:06:58.542646 [debug] [MainThread]: Flushing usage events
[0m08:06:59.735097 [debug] [MainThread]: An error was encountered while trying to flush usage events
